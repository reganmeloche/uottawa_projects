{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5137_full",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaVl0kZCATKp"
      },
      "source": [
        "# Run this cell and restart the kernel so it loads properly\n",
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6LbwdgDSDyA"
      },
      "source": [
        "# Root path for accessing and storing files\n",
        "ROOT_PATH = '/content/drive/MyDrive/Colab Notebooks/5137'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgqrsE4RL_01",
        "outputId": "f092f18b-d443-4d3a-a30a-9415fde9874a"
      },
      "source": [
        "# Optionally Setup GPU use\n",
        "import tensorflow as tf\n",
        "DEVICE_NAME = tf.test.gpu_device_name()\n",
        "if DEVICE_NAME != '/device:GPU:0':\n",
        "  DEVICE_NAME = '/cpu:0'\n",
        "  print('GPU device not found... using CPU')\n",
        "print('Found GPU at: {}'.format(DEVICE_NAME))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJlfFUfzAuPX"
      },
      "source": [
        "# Pre-Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU7_kLdoAy-X"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BigGqH4HAzqg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import math\n",
        "import spacy\n",
        "import csv\n",
        "import random\n",
        "import timeit\n",
        "import time \n",
        "import gc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.feature_selection import f_classif \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpqpmMnxA3tM",
        "outputId": "d97160c7-1f53-4d7c-a4e1-cf9aaa4198ec"
      },
      "source": [
        "# NLTK Downloads\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL_m99wZA4oI"
      },
      "source": [
        "# Load Spacy\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymfF-XxuA7He"
      },
      "source": [
        "## Data Import and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP0iAUWQA5bp"
      },
      "source": [
        "# Import the contract text\n",
        "import json\n",
        "\n",
        "data_path = f'{ROOT_PATH}/data/CUADv1.json'\n",
        "with open(data_path) as json_file:\n",
        "    contract_data = json.load(json_file)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGkxCldIA-Xn"
      },
      "source": [
        "# train_path = f'{ROOT_PATH}/data/train_separate_questions.json'\n",
        "# with open(train_path) as json_file:\n",
        "#     train_data = json.load(json_file)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQWaLs7IA_j5"
      },
      "source": [
        "# Elements to extract from CUAD set\n",
        "element_id_list = [0, 1, 2, 31, 33]\n",
        "# 0: Contract name\n",
        "# 1: Parties\n",
        "# 2: Agreement Date\n",
        "# 31: Source code escrow\n",
        "# 33: Audit rights\n",
        "\n",
        "element_dict = {\n",
        "    0: 'Contract Name',\n",
        "    1: 'Parties',\n",
        "    2: 'Agreement Date',\n",
        "    31: 'Source Code Escrow',\n",
        "    33: 'Audit Rights'\n",
        "}\n",
        "\n",
        "element_map = {\n",
        "    0: 0,\n",
        "    1: 1,\n",
        "    2: 2,\n",
        "    31: 5,\n",
        "    33: 6\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoWJ0PdHBIM-"
      },
      "source": [
        "## Parsing and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_LIVbuhBDqW"
      },
      "source": [
        "# Retrieve and parse a contract to extract needed information\n",
        "def get_contract_by_id(contract_id):\n",
        "  contracts = contract_data['data'] # list (510 contracts)\n",
        "\n",
        "  contract = contracts[contract_id] # dict (title, paragraphs)\n",
        "  contract_title = contract['title'] # string\n",
        "  paragraphs = contract['paragraphs'] # list\n",
        "\n",
        "  paragraph = paragraphs[0] # dict (qas, context)\n",
        "\n",
        "  qas = paragraph['qas'] # list (41 questions - each type)\n",
        "\n",
        "  # Extract only the qas that matter here (choose the ids)\n",
        "  new_qas = []\n",
        "  element_qas = [(i,q) for i,q in enumerate(qas) if i in element_id_list]\n",
        "  for i,q in element_qas: # Will filter this down to just the ones we want\n",
        "    answers = []\n",
        "    for a in q['answers']:\n",
        "      new_a = {\n",
        "          'text': a['text'],\n",
        "          'start_ind': a['answer_start'],\n",
        "          'end_ind': a['answer_start'] + len(a['text'])\n",
        "      }\n",
        "      answers.append(new_a)\n",
        "    \n",
        "    # This may need to get structured as a category-val dict...?\n",
        "    new_qa = {\n",
        "          'id': q['id'],\n",
        "          'category': element_dict[i],\n",
        "          'question': q['question'],\n",
        "          'is_impossible': q['is_impossible'],\n",
        "          'answers': answers\n",
        "    }\n",
        "    new_qas.append(new_qa)\n",
        "\n",
        "  # get the context and qas\n",
        "  return {\n",
        "      'id': contract_id,\n",
        "      'title': contract_title,\n",
        "      'context': paragraph['context'],\n",
        "      'qas': new_qas\n",
        "  }"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B57i6lyBKpI"
      },
      "source": [
        "def print_contract(contract, text_len=200):\n",
        "  # Num answerable qs\n",
        "  possible_answers = [x['id'] for x in contract['qas'] if x['is_impossible'] == False]\n",
        "\n",
        "  # Print info\n",
        "  print('\\nContract ID:', contract['id'])\n",
        "  print('\\nTitle:', contract['title'])\n",
        "  print('\\n------------------')\n",
        "  print(contract['context'][0:text_len])\n",
        "  print('\\n------------------')\n",
        "  for qa in contract['qas']:\n",
        "    answer_texts = [a['text'] for a in qa['answers']]\n",
        "    print(f'{qa[\"category\"]:25} {\" \".join(answer_texts)}')\n",
        "    \n",
        "  print('\\n============================')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi8JAwtvBRYL"
      },
      "source": [
        "## Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMz4aPv1BSxb"
      },
      "source": [
        "### Hand-crafted Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FPEB4W8BVaJ"
      },
      "source": [
        "# Helpers\n",
        "def contains_num(s):\n",
        "    return any(i.isdigit() for i in s)\n",
        "\n",
        "def print_feats(doc, feats):\n",
        "    rep_str = '{:<6} '*len(feats[0])\n",
        "    rep_str = '{:<20}' + rep_str\n",
        "    for i,f in enumerate(feats):\n",
        "        text = doc[i].text\n",
        "        print(rep_str.format(text, *f))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcXIhv5OBWwC"
      },
      "source": [
        "upos = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
        "\n",
        "all_deps = ['ROOT', 'nummod', '', 'compound', 'dobj', 'punct', 'det', 'nsubjpass', 'auxpass', 'agent', 'cc', 'conj', 'pobj', 'nmod', 'appos', 'prep', 'amod', 'poss', 'case', 'nsubj', 'advmod', 'pcomp', 'relcl', 'aux', 'oprd', 'mark', 'advcl', 'acl', 'neg', 'ccomp', 'xcomp', 'attr', 'dep', 'npadvmod', 'meta', 'acomp', 'preconj', 'prt', 'intj', 'expl', 'dative', 'predet', 'csubj', 'parataxis', 'quantmod', 'csubjpass']\n",
        "\n",
        "keyword_sets = [\n",
        "  ['agreement', 'license', 'sponsorship', 'distributor', 'joint', 'strategic', 'alliance', 'endorsement', 'content', 'maintenance'],\n",
        "  ['inc', 'llc', 'ltd', 'company', 'parties', 'party', 'distributor', 'collectively', 'corporation', 'management'],\n",
        "  ['laws', 'agreement', 'state', 'shall', 'governed', 'accordance', 'construed', 'law', 'principles'],\n",
        "  ['company', 'rights', 'right', 'property', 'title', 'shall', 'intellectual', 'agreement', 'interest'],\n",
        "  ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december'],\n",
        "  ['shall', 'records', 'reasonable', 'business', 'audit' ]\n",
        "]\n",
        "\n",
        "def get_handcrafted_features(doc):\n",
        "    all_feats = []\n",
        "\n",
        "    for token in doc:\n",
        "        features = []\n",
        "        text = token.text\n",
        "        isalpha = text.isalpha()\n",
        "\n",
        "        # binary feature for all uppercase\n",
        "        f1 = isalpha and text.isupper()\n",
        "        # binary feature for all lowercase\n",
        "        f2 = isalpha and text.islower()\n",
        "        # binary feature for mixed-case\n",
        "        f3 = isalpha and text != text.lower() and text != text.upper()\n",
        "        # binary feature - is it a number?\n",
        "        f4 = contains_num(text)\n",
        "\n",
        "        features.extend([f1,f2,f3,f4])\n",
        "\n",
        "        # Length features. Is it 1-2 chars? 3-4? 5-6? 7-8? 9-10? 11-12? 12+?\n",
        "        l = len(text)\n",
        "\n",
        "        for i in range(6):\n",
        "          next_feat = l > 2*i and l <= (2*i)+2\n",
        "          features.append(next_feat)\n",
        "        \n",
        "        features.append(l > 12)\n",
        "\n",
        "        # Special features\n",
        "        ## Is numeric\n",
        "        f5 = text.isnumeric()\n",
        "        features.append(f5)\n",
        "\n",
        "        ## Special character\n",
        "        f6 = l == 1 and not text.isalpha() and not text.isnumeric()\n",
        "        features.append(f6)\n",
        "\n",
        "        ## Stop-word\n",
        "        f7 = text in nlp.Defaults.stop_words\n",
        "        features.append(f7)\n",
        "\n",
        "        # one-hot encode the pos types\n",
        "        for up in upos:\n",
        "          fp = 1 if token.pos_ == up else 0\n",
        "          features.append(fp)\n",
        "\n",
        "        # Check the keyword sets\n",
        "        for ks in keyword_sets:\n",
        "          f8 = text in ks\n",
        "          features.append(f8)\n",
        "        \n",
        "        # one-hot encode the dependency types (Removed)\n",
        "        # for dep in all_deps:\n",
        "        #   fp = 1 if token.dep_ == dep else 0\n",
        "        #   features.append(fp)\n",
        "\n",
        "        all_feats.append(features)\n",
        "\n",
        "    all_feats = np.array(all_feats)\n",
        "    all_feats = all_feats.astype(int)\n",
        "\n",
        "    return all_feats\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx4AbP63BhZA"
      },
      "source": [
        "### Feature Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x8f0a8oBYct"
      },
      "source": [
        "# Find the token spans of the answers\n",
        "def get_answer_spans(doc, answers):\n",
        "  t_spans = []\n",
        "  for ans in answers:\n",
        "    start_ind = ans['start_ind']\n",
        "    end_ind = ans['end_ind']\n",
        "  \n",
        "    # get token start and end\n",
        "    tokens_a = [t.i for t in doc if t.idx >= start_ind]\n",
        "    tokens_b = [t.i for t in doc if t.idx <= end_ind]\n",
        "    t_span = [value for value in tokens_a if value in tokens_b]\n",
        "    t_spans.append(t_span)\n",
        "  \n",
        "  return t_spans"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNP8dRnABjZV"
      },
      "source": [
        "# Get the embedding vectors for all tokens in a contract\n",
        "def get_embedding_vectors(tokenizer, embedding_matrix, doc, t, window_offset = 3):\n",
        "  # Result will be a long flat 1D vector of size v_dim x window_size\n",
        "  res = []\n",
        "\n",
        "  n_dim = len(embedding_matrix[0])\n",
        "\n",
        "  for k in range(-window_offset, window_offset+1):\n",
        "    target = t.i + k\n",
        "\n",
        "    vec = np.zeros(n_dim)\n",
        "\n",
        "    if target > 0 and target < len(doc):\n",
        "      text = doc[target].text.lower()\n",
        "\n",
        "      if text in tokenizer.word_index:\n",
        "        tok = tokenizer.word_index[text]\n",
        "        vec = embedding_matrix[tok]\n",
        "\n",
        "    res.extend(vec)\n",
        "  \n",
        "  return res"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKckr3h6Bmjc"
      },
      "source": [
        "# Extract a sliding window from the list of hand-crafted features\n",
        "def get_hcf_vecs(hcf, t, window_offset=5):\n",
        "  default_len = len(hcf[0])\n",
        "\n",
        "  res = []\n",
        "\n",
        "  for j in range(-window_offset, window_offset+1):\n",
        "    target = t.i + j\n",
        "    if target >= 0 and target < len(hcf):\n",
        "      res.extend(hcf[target])\n",
        "    else:\n",
        "      res.extend(np.zeros(default_len))\n",
        "  \n",
        "  return res\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXT-iGbfBmzE"
      },
      "source": [
        "# Get all of the features from a contract document\n",
        "## Concats the window of hand-crafted features with the window of embedding vecs\n",
        "def get_features(tokenizer, embedding_matrix, doc, do_hcf=True, do_emb=True):\n",
        "  hcf = get_handcrafted_features(doc)\n",
        "  def_len = len(hcf[0])\n",
        "\n",
        "  all_fv = []\n",
        "\n",
        "  # Full size will be 2*x + 1\n",
        "  embedding_window_offset = 5\n",
        "  hcf_window_offset = 5\n",
        "\n",
        "  for t in doc:\n",
        "    # Feature vector\n",
        "    fv = []\n",
        "\n",
        "    # Get the vector embeddings in sliding window\n",
        "    if do_emb:\n",
        "      emb_vecs = get_embedding_vectors(tokenizer, embedding_matrix, doc, t, embedding_window_offset)\n",
        "      fv.extend(emb_vecs)\n",
        "\n",
        "    # Get HCF vectors \n",
        "    if do_hcf:\n",
        "      hcf_vecs = get_hcf_vecs(hcf, t, hcf_window_offset)\n",
        "      fv.extend(hcf_vecs)\n",
        "    \n",
        "    fv = np.array(fv)\n",
        "    all_fv.append(fv)\n",
        "\n",
        "  return all_fv"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWq5AgPqBnp7"
      },
      "source": [
        "# Get the target labels from a contract document\n",
        "def get_labels(contract, element_id, doc):\n",
        "  labels = []\n",
        "\n",
        "  qa = contract['qas'][element_id]\n",
        "\n",
        "  # Get the span of the answer tokens\n",
        "  # Concatenate together so we have a list of tokens that are part of the label\n",
        "  answers = qa['answers']\n",
        "  answer_spans = get_answer_spans(doc, answers)\n",
        "  concat_ans_spans = np.concatenate(answer_spans) if len(answer_spans) > 0 else []\n",
        "  \n",
        "  for t in doc:\n",
        "    # Get the label\n",
        "    if t.i in concat_ans_spans:\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "  \n",
        "  return labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjWpjBJ4BtBe"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCnB_uHdBvXL"
      },
      "source": [
        "### Filter and Tokenize Contracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG5A_5euBokI"
      },
      "source": [
        "# Get all the contracts and nlp docs.. This operation takes about 3 minutes\n",
        "def get_contracts_and_docs(max_doc_length=100000):\n",
        "  all_contracts = []\n",
        "  nlp_set = []\n",
        "\n",
        "  for i in range(510):\n",
        "    next_contract = get_contract_by_id(i) \n",
        "\n",
        "    if len(next_contract['context']) < max_doc_length:\n",
        "      all_contracts.append(next_contract)\n",
        "      nlp_set.append(nlp(next_contract['context']))\n",
        "  \n",
        "    if i%20==0: print(i)\n",
        "  print('Total Contracts:', len(all_contracts))\n",
        "\n",
        "  return all_contracts, nlp_set\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHTPvPxaE9Vl"
      },
      "source": [
        "# Get all contracts that contain a specified element\n",
        "def get_contracts_docs_with_element(contracts, docs, element_id):\n",
        "  new_contracts = []\n",
        "  new_docs = []\n",
        "  for i,c in enumerate(contracts):\n",
        "    answers = c['qas'][element_id]['answers']\n",
        "    if len(answers) > 0:\n",
        "      new_contracts.append(c)\n",
        "      new_docs.append(docs[i])\n",
        "  return new_contracts, new_docs\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXeuMHoxB5HZ"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wU9xeY8B037"
      },
      "source": [
        "# Get the pre-trained embedding and build the tokenizer\n",
        "def get_embeddings_and_tokenizer(all_contracts, embedding_size=50):\n",
        "  assert(embedding_size in [50,100,200,300])\n",
        "  tokenizer = Tokenizer()\n",
        "\n",
        "  texts = [c['context'].lower() for c in all_contracts]\n",
        "\n",
        "  tokenizer.fit_on_texts(texts)\n",
        "\n",
        "  # Bring in embedding\n",
        "  glove_path = f'{ROOT_PATH}/glove/glove.6B.{embedding_size}d.txt'\n",
        "  embeddings_index = dict()\n",
        "  f = open(glove_path)\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "  f.close()\n",
        "  print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "  vocab_size = len(tokenizer.word_index)\n",
        "  print('Vocab size:', vocab_size)\n",
        "\n",
        "  # Build embedding matrix - probably store this...\n",
        "  embedding_matrix = np.zeros((vocab_size+1, embedding_size))\n",
        "  for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "  \n",
        "  return embedding_matrix, tokenizer\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYtyNAH7B8Ha"
      },
      "source": [
        "### Build Features for Element"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4xZ2PhjB6Uy"
      },
      "source": [
        "# Token windows to look for each element\n",
        "doc_ranges = [\n",
        "  [0,1000],\n",
        "  [0,1600],\n",
        "  [0,3000],\n",
        "  [300,13000],\n",
        "  [400,12000]\n",
        "]\n",
        "\n",
        "# Flags to use hand-crafted features and embeddings\n",
        "do_hcf = True\n",
        "do_emb = True\n",
        "\n",
        "# Get all features and labels for an element\n",
        "## This function can take a long time on a large dataset\n",
        "def get_features_labels_for_element(contracts, docs, tokenizer, embedding_matrix, element_id):\n",
        "  doc_range = doc_ranges[element_id]\n",
        "\n",
        "  features = []\n",
        "  labels = []\n",
        "\n",
        "  for i, contract in enumerate(contracts):\n",
        "    doc = docs[i]\n",
        "    doc_sub = doc[doc_range[0]: doc_range[1]]\n",
        "  \n",
        "    next_fv = get_features(tokenizer, embedding_matrix, doc_sub, do_hcf, do_emb)\n",
        "    next_labels = get_labels(contract, element_id, doc_sub)\n",
        "    \n",
        "    features.extend(next_fv)\n",
        "    labels.extend(next_labels)\n",
        "    if i%10==0: print(i)\n",
        "  \n",
        "  return features, labels"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wckaM1MSCH91"
      },
      "source": [
        "### Saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eug6o4h7CGAA"
      },
      "source": [
        "import pickle\n",
        "\n",
        "def save_obj(obj, filename):\n",
        "  save_path = f'{ROOT_PATH}/stored/{filename}.pkl'\n",
        "  with open(save_path, 'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "  print('Saved')\n",
        "\n",
        "def load_obj(filename):\n",
        "  load_path = f'{ROOT_PATH}/stored/{filename}.pkl'\n",
        "  with open(load_path, 'rb') as f:\n",
        "    obj = pickle.load(f)\n",
        "  return obj\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecD8pjCgCN-H"
      },
      "source": [
        "## Execution Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmtGl2_Y8x8p"
      },
      "source": [
        "# Split data into folds\n",
        "def get_k_folds(num_folds, X, y):\n",
        "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
        "    skf.get_n_splits(X,y)\n",
        "\n",
        "    result = []\n",
        "    \n",
        "    for train_index, test_index in skf.split(X,y):\n",
        "        result.append({ \"train\": train_index, \"test\": test_index })\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gygs9VwDCPua"
      },
      "source": [
        "# Evaluate a model using test and pred sets\n",
        "## Accuracy, precision, recall, f1, runtime\n",
        "def evaluate(y_test, y_pred, runtime):\n",
        "  cf = metrics.classification_report(y_test, y_pred)\n",
        "  #print(cf)\n",
        "  \n",
        "  scores = metrics.precision_recall_fscore_support(y_test, y_pred, pos_label=1, average='binary')\n",
        "  acc = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "  result = {\n",
        "      'acc': round(acc,3),\n",
        "      'prec': round(scores[0],3),\n",
        "      'rec': round(scores[1],3),\n",
        "      'f1': round(scores[2],3),\n",
        "      'rt': round(runtime)\n",
        "  }\n",
        "\n",
        "  return result"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WES0OFcRCRA2"
      },
      "source": [
        "# Process a set of model results \n",
        "def process_results(models, results):\n",
        "  final_res = {}\n",
        "\n",
        "  for model in models:    \n",
        "    model_res = {}\n",
        "    # prob add runtime here too\n",
        "    for key in ['acc', 'prec', 'rec', 'f1', 'rt']:\n",
        "      model_res[key] = round(results[model][key], 3)\n",
        "\n",
        "    final_res[model] = model_res\n",
        "\n",
        "  return final_res\n",
        "\n",
        "def avg_round(lst):\n",
        "  return round(sum(lst) / len(lst), 3)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VhNOf3cZp13"
      },
      "source": [
        "# Process a list of results into average values\n",
        "def process_iter_results(models, results):\n",
        "  final_res = {}\n",
        "\n",
        "  for model in models:\n",
        "    model_res = {}\n",
        "\n",
        "    for key in ['acc', 'prec', 'rec', 'f1', 'rt']:\n",
        "      all_vals = [x[model][key] for x in results]\n",
        "      model_res[key] = avg_round(all_vals)\n",
        "    \n",
        "    final_res[model] = model_res\n",
        "\n",
        "  return final_res"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Di-HpAzCTN9"
      },
      "source": [
        "# Print a result set\n",
        "def print_results(results):\n",
        "  print('\\n')\n",
        "  for k in results.keys():\n",
        "    print('\\n')\n",
        "    print(k)\n",
        "    for m in results[k].keys():\n",
        "      print(f'{m}: {results[k][m]}')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sbuiAmqCVWZ"
      },
      "source": [
        "# Run and time a model\n",
        "def run_model(model, X_train, X_test, y_train, y_test):\n",
        "  start = timeit.default_timer()\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  stop = timeit.default_timer()\n",
        "  runtime = (stop - start)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  return evaluate(y_test, y_pred, runtime)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSQ8WhCNCWWZ"
      },
      "source": [
        "# Run a single iteration of a model\n",
        "def execute(model_set, X, y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, shuffle=True)\n",
        "\n",
        "  # Scale the data\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "\n",
        "  results = {}\n",
        "\n",
        "  for m in model_set.keys():\n",
        "    print('running: ', m)\n",
        "    model = model_set[m]\n",
        "    results[m] = run_model(model, X_train, X_test, y_train, y_test)\n",
        "  \n",
        "  return results\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HF7Blp84epv"
      },
      "source": [
        "## Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFWco50Q52hd"
      },
      "source": [
        "### Dimensionality Reduction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ7Y1w8e4hFu"
      },
      "source": [
        "# Feature selection\n",
        "def select_features(X, y, percentile, do_print=False):\n",
        "  fs = SelectPercentile(score_func=chi2, percentile=percentile)\n",
        "  X_sel = fs.fit_transform(X, y)\n",
        "\n",
        "  # Print\n",
        "  # Show the feature rankings\n",
        "  if do_print:\n",
        "    print('Feature ranking:')\n",
        "    for i in range(len(fs.scores_)):\n",
        "        print('Feature %d: %f' % (i, fs.scores_[i]))\n",
        "\n",
        "    print('\\nNumerical data sample:')\n",
        "    print(X[0:2])\n",
        "    print('\\nSelected numerical data sample:')\n",
        "    print(X_sel[0:2])\n",
        "\n",
        "  return X_sel"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4qqOYca4jJN"
      },
      "source": [
        "# PCA\n",
        "def perform_pca(X, percent=0.97):\n",
        "  print('init', len(X[0]))\n",
        "  #nc = int(len(X[0])*0.75)\n",
        "  pca = PCA(n_components=percent, svd_solver='full')\n",
        "\n",
        "  new_X = pca.fit_transform(X)\n",
        "  print('new', len(new_X[0]))\n",
        "  return new_X, pca"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yir38vkH5vao"
      },
      "source": [
        "### Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFtR2UM357a3"
      },
      "source": [
        "# Smote underbalancing\n",
        "def undersample(X, y, percent=0.1):\n",
        "\n",
        "  u,c = np.unique(y, return_counts=True)\n",
        "  print(u,c, len(X))\n",
        "  \n",
        "  # fit and apply the transform\n",
        "  try:\n",
        "    sm = RandomUnderSampler(sampling_strategy=percent)\n",
        "    newX, newY = sm.fit_resample(X, y)\n",
        "  except:\n",
        "    print('** Sampling error...')\n",
        "    newX = np.copy(X)\n",
        "    newY = np.copy(y)\n",
        "\n",
        "  u,c = np.unique(newY, return_counts=True)\n",
        "  print(u,c, len(newX))\n",
        "\n",
        "  return newX, newY"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCHaThsOR73p"
      },
      "source": [
        "## Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uHn9ysFR-lY"
      },
      "source": [
        "# Run a statistical test on fold results\n",
        "## Performs Friedman or Wilcoxon signed-rank (if n = 2)\n",
        "def run_stats(all_results, metric_name):\n",
        "    print('--Stat test:', metric_name)\n",
        "    all_models = all_results[0].keys()\n",
        "    n = len(all_models) # num algs\n",
        "    num_folds = len(all_results) # num folds\n",
        "\n",
        "    a = np.zeros((n, num_folds))\n",
        "    wa = np.zeros((n, num_folds))\n",
        "    rank_sums = np.zeros(n)\n",
        "    \n",
        "    # Friedman critical value\n",
        "    critical_value = 10.8\n",
        "    \n",
        "    # Build the desired result set\n",
        "    # Collect the right metric\n",
        "    for i, res in enumerate(all_results):\n",
        "        for j, m in enumerate(all_models):\n",
        "            a[j][i] = round(res[m][metric_name], 3)\n",
        "            wa[j][i] = res[m][metric_name]\n",
        "\n",
        "    # Print the results data frame\n",
        "    d = {}\n",
        "    for i, m in enumerate(all_models):\n",
        "      d[m] = a[i]\n",
        "    result_df = pd.DataFrame(data = d)\n",
        "    print('\\n---------')\n",
        "    print(result_df)\n",
        "    \n",
        "    # Print the average values\n",
        "    avgs = [round(sum(x) / len(x), 3) for x in a]\n",
        "    print(avgs)\n",
        "\n",
        "    # Wilcoxon Signed Rank test. Use if n == 2\n",
        "    if n == 2:\n",
        "      w_cv = 8\n",
        "      print('Using Wilcoxon signed-rank test')\n",
        "      w_val = stats.wilcoxon(wa[0], wa[1], zero_method='zsplit')\n",
        "      print('Wilcoxon value:', w_val)\n",
        "      return w_val.statistic < w_cv\n",
        "    \n",
        "    # Friedman test\n",
        "    # Perform the ranking\n",
        "    for i in range(0, num_folds):\n",
        "        # convert to dict\n",
        "        vals = a[:,i]\n",
        "        temp = {}\n",
        "        for j in range(0,n):\n",
        "            temp[j] = vals[j]\n",
        "            \n",
        "        # Rank them\n",
        "        sorted_temp = {k: v for k, v in sorted(temp.items(), key=lambda item: item[1], reverse=True)}\n",
        "        sorted_keys = list(sorted_temp.keys())\n",
        "        \n",
        "        # Add to rank sums\n",
        "        for k in range(0,n):\n",
        "            rank_sums[sorted_keys[k]] += (k+1)\n",
        "    \n",
        "    rank_sums = [x/num_folds for x in rank_sums]\n",
        "    \n",
        "    # Print the ranks (for Nemenyi)\n",
        "    print(rank_sums)\n",
        "    \n",
        "    # Calculate the Friedman Quantities\n",
        "    r1 = (n + 1) / 2\n",
        "        \n",
        "    r2 = 0\n",
        "    for i in range(0, n):\n",
        "        r2 += math.pow(rank_sums[i] - r1, 2)\n",
        "    r2 = r2 * num_folds\n",
        "    \n",
        "    r3 = 0\n",
        "    for i in range(0, n):\n",
        "        r3 += math.pow( (i+1) - r1, 2)\n",
        "    r3 = r3 * num_folds\n",
        "    r3 = r3 / ((n - 1) * (num_folds))\n",
        "    \n",
        "    # Obtain two values: One is custom-coded and the other is from the scipy library\n",
        "    custom_stat = r2 / r3\n",
        "    #scipy_stat = stats.friedmanchisquare(a[0], a[1], a[2], a[3], a[4], a[5])\n",
        "    scipy_stat = stats.friedmanchisquare(*a)\n",
        "\n",
        "    print('Using Friedman test')\n",
        "    print('Scipy:', scipy_stat)\n",
        "    \n",
        "    return custom_stat > critical_value"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWjc6MtD8E2t"
      },
      "source": [
        "### REMOVE??\n",
        "# Run a statistical test on fold results\n",
        "## Performs Friedman and Wilcoxon signed-rank\n",
        "## results: { 'DT': {'tpr': 0.88, 'tnr': 0.76...}, 'RF': {}, ...}\n",
        "def run_stats_balance(all_results, metric_name):\n",
        "    print('--Stat test:', metric_name)\n",
        "    all_models = all_results[0].keys()\n",
        "    n = len(all_models) # num algs\n",
        "    num_folds = len(all_results) # num folds\n",
        "\n",
        "    a = np.zeros((n, num_folds))\n",
        "    wa = np.zeros((n, num_folds))\n",
        "    rank_sums = np.zeros(n)\n",
        "    \n",
        "    # Friedman critical value\n",
        "    critical_value = 10.8\n",
        "    \n",
        "    # Build the desired result set\n",
        "    # Collect the right metric\n",
        "    for i, res in enumerate(all_results):\n",
        "        for j, m in enumerate(all_models):\n",
        "            a[j][i] = round(res[m][metric_name], 3)\n",
        "            wa[j][i] = res[m][metric_name]\n",
        "\n",
        "    # Print the results data frame\n",
        "    d = {}\n",
        "    for i, m in enumerate(all_models):\n",
        "      d[m] = a[i]\n",
        "    result_df = pd.DataFrame(data = d)\n",
        "    print('\\n---------')\n",
        "    print(result_df)\n",
        "    \n",
        "    # Print the average values\n",
        "    avgs = [round(sum(x) / len(x), 3) for x in a]\n",
        "    print(avgs)\n",
        "\n",
        "    # Wilcoxon Signed Rank test. Use if n == 2\n",
        "    if n == 2:\n",
        "      w_cv = 8\n",
        "      print('Using Wilcoxon signed-rank test')\n",
        "      w_val = stats.wilcoxon(wa[0], wa[1], zero_method='zsplit')\n",
        "      print('Wilcoxon value:', w_val)\n",
        "      return w_val.statistic < w_cv\n",
        "    \n",
        "    # Friedman test\n",
        "    # Perform the ranking\n",
        "    for i in range(0, num_folds):\n",
        "        # convert to dict\n",
        "        vals = a[:,i]\n",
        "        temp = {}\n",
        "        for j in range(0,n):\n",
        "            temp[j] = vals[j]\n",
        "            \n",
        "        # Rank them\n",
        "        sorted_temp = {k: v for k, v in sorted(temp.items(), key=lambda item: item[1], reverse=True)}\n",
        "        sorted_keys = list(sorted_temp.keys())\n",
        "        \n",
        "        # Add to rank sums\n",
        "        for k in range(0,n):\n",
        "            rank_sums[sorted_keys[k]] += (k+1)\n",
        "    \n",
        "    rank_sums = [x/num_folds for x in rank_sums]\n",
        "    \n",
        "    # Print the ranks (for Nemenyi)\n",
        "    print(rank_sums)\n",
        "    \n",
        "    # Calculate the Friedman Quantities\n",
        "    r1 = (n + 1) / 2\n",
        "        \n",
        "    r2 = 0\n",
        "    for i in range(0, n):\n",
        "        r2 += math.pow(rank_sums[i] - r1, 2)\n",
        "    r2 = r2 * num_folds\n",
        "    \n",
        "    r3 = 0\n",
        "    for i in range(0, n):\n",
        "        r3 += math.pow( (i+1) - r1, 2)\n",
        "    r3 = r3 * num_folds\n",
        "    r3 = r3 / ((n - 1) * (num_folds))\n",
        "    \n",
        "    # Obtain two values: One is custom-coded and the other is from the scipy library\n",
        "    custom_stat = r2 / r3\n",
        "    #scipy_stat = stats.friedmanchisquare(a[0], a[1], a[2], a[3], a[4], a[5])\n",
        "    scipy_stat = stats.friedmanchisquare(*a)\n",
        "\n",
        "    print('Using Friedman test')\n",
        "    print('Scipy:', scipy_stat)\n",
        "    \n",
        "    return custom_stat > critical_value"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RE_nKD1CKMz"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCTitYOk1I7C"
      },
      "source": [
        "## Experiment Setup\n",
        "Run these cells before running each experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBz3yfPJ1KIu",
        "outputId": "6712baf7-ced7-4737-b88a-848532afb03b"
      },
      "source": [
        "model_parm = 25 #20\n",
        "embedding_size = 100 \n",
        "num_folds = 5\n",
        "subset_size = 50 \n",
        "\n",
        "model_set = {\n",
        "  'dt': DecisionTreeClassifier(max_depth=model_parm),\n",
        "  'sv': SVC(max_iter=model_parm),\n",
        "  'lr': LogisticRegression(max_iter=model_parm),\n",
        "  'mlp': MLPClassifier(max_iter=model_parm) \n",
        "}\n",
        "\n",
        "# Get globals\n",
        "contracts = load_obj('contracts')\n",
        "docs = load_obj('docs')\n",
        "embedding_matrix, tokenizer = get_embeddings_and_tokenizer(contracts, embedding_size)\n",
        "\n",
        "print('Number of contracts: ', len(contracts))\n",
        "print('Vocab length: ', len(tokenizer.word_index))\n",
        "print('Embedding size: ', embedding_matrix.shape)\n",
        "\n",
        "# Get all contracts/docs for the element\n",
        "element_id = 1\n",
        "elem_contracts, elem_docs = get_contracts_docs_with_element(contracts, docs, element_id)\n",
        "print('Num contracts considered:', len(elem_contracts))\n",
        "\n",
        "if subset_size > 0:\n",
        "  elem_contracts = elem_contracts[0:subset_size]\n",
        "  elem_docs = elem_docs[0:subset_size]\n",
        "\n",
        "print('Subset num contracts considered:', len(elem_contracts))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of contracts:  429\n",
            "Vocab length:  25441\n",
            "Embedding size:  (25442, 50)\n",
            "Num contracts considered: 428\n",
            "Subset num contracts considered: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBLL17OK1ddB",
        "outputId": "dbdfa8e0-1fd6-466e-a56d-15c5d1508aaa"
      },
      "source": [
        "# Build the features\n",
        "features, labels = get_features_labels_for_element(elem_contracts, elem_docs, tokenizer, embedding_matrix, element_id)\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "print('Initial data shape:', X.shape)\n",
        "print('----')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "Initial data shape: (75285, 957)\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7-eQAoOlfWV"
      },
      "source": [
        "# Process results of experiment\n",
        "def process_exp_results(val_list, models, results):\n",
        "  final_res = {}\n",
        "\n",
        "  for val in val_list:\n",
        "    val_res = {}\n",
        "    for model in models:\n",
        "      model_res = {}\n",
        "      for metric in ['acc', 'rec', 'prec', 'f1', 'rt']:\n",
        "        next_r = [x[model][val][metric] for x in results]\n",
        "        model_res[metric] = avg_round(next_r)\n",
        "\n",
        "      val_res[model] = model_res\n",
        "    \n",
        "    final_res[val] = val_res\n",
        "  \n",
        "  return final_res"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etl9rgyTD472"
      },
      "source": [
        "## Balance Experiment\n",
        "Find the optimal level of imbalance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "8o0lNSPm0-4H",
        "outputId": "f2d512de-b425-43ba-88ee-a41844783620"
      },
      "source": [
        "folds = get_k_folds(num_folds, X, y)\n",
        "\n",
        "fold_results = []\n",
        "\n",
        "for i in range(num_folds):\n",
        "  print(f'\\n ===== FOLD {i} =====')\n",
        "\n",
        "  # Get the sets from the fold\n",
        "  X_train, X_test = X[folds[i]['train']], X[folds[i]['test']]\n",
        "  y_train, y_test = y[folds[i]['train']], y[folds[i]['test']]\n",
        "\n",
        "  # Scale\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "\n",
        "  # Undersampling\n",
        "  Xt05, yt05 = undersample(X_train, y_train, 0.05)\n",
        "  Xt1, yt1 = undersample(X_train, y_train, 0.1)\n",
        "  Xt25, yt25 = undersample(X_train, y_train, 0.25)\n",
        "\n",
        "  # Run all the models\n",
        "  model_results = {}\n",
        "  for m in model_set.keys():\n",
        "    model_results[m] = {}\n",
        "    print('running: ', m)\n",
        "    model = model_set[m]\n",
        "    model_results[m]['0'] = run_model(model, X_train, X_test, y_train, y_test)\n",
        "    model_results[m]['0.05'] = run_model(model, Xt05, X_test, yt05, y_test)\n",
        "    model_results[m]['0.1'] = run_model(model, Xt1, X_test, yt1, y_test)\n",
        "    model_results[m]['0.25'] = run_model(model, Xt25, X_test, yt25, y_test)\n",
        "\n",
        "  fold_results.append(model_results)\n",
        "\n",
        "print(fold_results)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 0 =====\n",
            "[0 1] [59363   865] 60228\n",
            "[0 1] [17300   865] 18165\n",
            "[0 1] [59363   865] 60228\n",
            "[0 1] [8650  865] 9515\n",
            "[0 1] [59363   865] 60228\n",
            "[0 1] [3460  865] 4325\n",
            "running:  dt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-a5f285cd26fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmodel_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0.05'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmodel_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0.1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-4e540fadf17f>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQI40H7I0owQ"
      },
      "source": [
        "for m in model_set.keys():\n",
        "  print('\\nModel', m)\n",
        "  stat_set = [res[m] for res in fold_results ]\n",
        "  run_stats(stat_set, 'rec')\n",
        "  run_stats(stat_set, 'f1')\n",
        "\n",
        "bal_list = ['0', '0.05', '0.1', '0.25']\n",
        "balance_results = process_exp_results(bal_list, model_set.keys(), fold_results)\n",
        "\n",
        "print(balance_results)\n",
        "\n",
        "for bal in bal_list:\n",
        "  print(f'\\n\\n====== Bal = {bal} ========')\n",
        "  print_results(balance_results[bal])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaGxSYHQWreL"
      },
      "source": [
        "save_obj(fold_results, 'balance_exp_results')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3WdlqJWyfF"
      },
      "source": [
        "## HCF Experiment\n",
        "Find the optimal configuration of hand-crafted features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfWXZy2uXQ8O",
        "outputId": "2994fb4f-7c7b-4c55-8714-7c00b0cb6f03"
      },
      "source": [
        "# Build the datasets\n",
        "\n",
        "start_ind = embedding_size * 11\n",
        "\n",
        "X_hcf = X[:,start_ind:]\n",
        "\n",
        "X90 = select_features(X_hcf, y, 90)\n",
        "\n",
        "X75 = select_features(X_hcf, y, 75)\n",
        "\n",
        "print('90%', len(X90[0]))\n",
        "print('75%', len(X75[0]))\n",
        "print(X_hcf.shape)\n"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90% 366\n",
            "75% 305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TsMvlBqJW0mg",
        "outputId": "d9bc4f73-5aed-41bb-d811-0459ee3817c0"
      },
      "source": [
        "# Split three sets: original, 90%, 75%\n",
        "folds = get_k_folds(num_folds, X_hcf, y)\n",
        "\n",
        "fold_results = []\n",
        "\n",
        "for i in range(num_folds):\n",
        "  print(f'\\n ===== FOLD {i} =====')\n",
        "\n",
        "  # Get the sets from the fold\n",
        "  X_train, X_test = X_hcf[folds[i]['train']], X_hcf[folds[i]['test']]\n",
        "  X90_train, X90_test = X90[folds[i]['train']], X90[folds[i]['test']]\n",
        "  X75_train, X75_test = X75[folds[i]['train']], X75[folds[i]['test']]\n",
        "  y_train, y_test = y[folds[i]['train']], y[folds[i]['test']]\n",
        "\n",
        "  # Scale\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "\n",
        "  # Scale\n",
        "  sc90 = StandardScaler()\n",
        "  X90_train = sc90.fit_transform(X90_train)\n",
        "  X90_test = sc90.transform(X90_test)\n",
        "\n",
        "  # Scale\n",
        "  sc75 = StandardScaler()\n",
        "  X75_train = sc75.fit_transform(X75_train)\n",
        "  X75_test = sc75.transform(X75_test)\n",
        "\n",
        "  model_results = {}\n",
        "  for m in model_set.keys():\n",
        "    model_results[m] = {}\n",
        "    print('running: ', m)\n",
        "    model = model_set[m]\n",
        "    model_results[m]['100'] = run_model(model, X_train, X_test, y_train, y_test)\n",
        "    model_results[m]['90'] = run_model(model, X90_train, X90_test, y_train, y_test)\n",
        "    model_results[m]['75'] = run_model(model, X75_train, X75_test, y_train, y_test)\n",
        "\n",
        "  fold_results.append(model_results)\n",
        "\n",
        "print(fold_results)\n",
        "print(balance_results)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 0 =====\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 1 =====\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 2 =====\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 3 =====\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 4 =====\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'dt': {'100': {'acc': 0.984, 'prec': 0.38, 'rec': 0.382, 'f1': 0.381, 'rt': 18}, '90': {'acc': 0.984, 'prec': 0.383, 'rec': 0.377, 'f1': 0.38, 'rt': 15}, '75': {'acc': 0.983, 'prec': 0.355, 'rec': 0.364, 'f1': 0.36, 'rt': 11}}, 'sv': {'100': {'acc': 0.957, 'prec': 0.064, 'rec': 0.168, 'f1': 0.093, 'rt': 2}, '90': {'acc': 0.956, 'prec': 0.047, 'rec': 0.127, 'f1': 0.069, 'rt': 2}, '75': {'acc': 0.984, 'prec': 0.125, 'rec': 0.034, 'f1': 0.053, 'rt': 2}}, 'lr': {'100': {'acc': 0.988, 'prec': 0.639, 'rec': 0.178, 'f1': 0.279, 'rt': 1}, '90': {'acc': 0.988, 'prec': 0.648, 'rec': 0.176, 'f1': 0.276, 'rt': 1}, '75': {'acc': 0.988, 'prec': 0.685, 'rec': 0.163, 'f1': 0.263, 'rt': 1}}, 'mlp': {'100': {'acc': 0.988, 'prec': 0.526, 'rec': 0.367, 'f1': 0.432, 'rt': 50}, '90': {'acc': 0.988, 'prec': 0.576, 'rec': 0.344, 'f1': 0.43, 'rt': 45}, '75': {'acc': 0.987, 'prec': 0.488, 'rec': 0.416, 'f1': 0.449, 'rt': 35}}}, {'dt': {'100': {'acc': 0.984, 'prec': 0.365, 'rec': 0.344, 'f1': 0.354, 'rt': 17}, '90': {'acc': 0.984, 'prec': 0.364, 'rec': 0.336, 'f1': 0.349, 'rt': 15}, '75': {'acc': 0.983, 'prec': 0.34, 'rec': 0.331, 'f1': 0.336, 'rt': 12}}, 'sv': {'100': {'acc': 0.963, 'prec': 0.074, 'rec': 0.16, 'f1': 0.101, 'rt': 2}, '90': {'acc': 0.938, 'prec': 0.036, 'rec': 0.147, 'f1': 0.058, 'rt': 2}, '75': {'acc': 0.975, 'prec': 0.063, 'rec': 0.067, 'f1': 0.065, 'rt': 2}}, 'lr': {'100': {'acc': 0.988, 'prec': 0.689, 'rec': 0.189, 'f1': 0.296, 'rt': 1}, '90': {'acc': 0.988, 'prec': 0.693, 'rec': 0.181, 'f1': 0.287, 'rt': 1}, '75': {'acc': 0.988, 'prec': 0.663, 'rec': 0.168, 'f1': 0.268, 'rt': 1}}, 'mlp': {'100': {'acc': 0.988, 'prec': 0.549, 'rec': 0.331, 'f1': 0.413, 'rt': 48}, '90': {'acc': 0.985, 'prec': 0.424, 'rec': 0.346, 'f1': 0.381, 'rt': 46}, '75': {'acc': 0.988, 'prec': 0.535, 'rec': 0.359, 'f1': 0.43, 'rt': 35}}}, {'dt': {'100': {'acc': 0.983, 'prec': 0.344, 'rec': 0.349, 'f1': 0.347, 'rt': 15}, '90': {'acc': 0.983, 'prec': 0.354, 'rec': 0.359, 'f1': 0.356, 'rt': 11}, '75': {'acc': 0.983, 'prec': 0.343, 'rec': 0.328, 'f1': 0.336, 'rt': 11}}, 'sv': {'100': {'acc': 0.982, 'prec': 0.108, 'rec': 0.057, 'f1': 0.075, 'rt': 2}, '90': {'acc': 0.945, 'prec': 0.051, 'rec': 0.183, 'f1': 0.08, 'rt': 2}, '75': {'acc': 0.96, 'prec': 0.07, 'rec': 0.168, 'f1': 0.099, 'rt': 2}}, 'lr': {'100': {'acc': 0.988, 'prec': 0.616, 'rec': 0.199, 'f1': 0.301, 'rt': 1}, '90': {'acc': 0.988, 'prec': 0.632, 'rec': 0.191, 'f1': 0.294, 'rt': 1}, '75': {'acc': 0.988, 'prec': 0.606, 'rec': 0.171, 'f1': 0.266, 'rt': 1}}, 'mlp': {'100': {'acc': 0.988, 'prec': 0.584, 'rec': 0.385, 'f1': 0.464, 'rt': 48}, '90': {'acc': 0.989, 'prec': 0.6, 'rec': 0.341, 'f1': 0.435, 'rt': 46}, '75': {'acc': 0.988, 'prec': 0.579, 'rec': 0.341, 'f1': 0.429, 'rt': 36}}}, {'dt': {'100': {'acc': 0.984, 'prec': 0.398, 'rec': 0.396, 'f1': 0.397, 'rt': 16}, '90': {'acc': 0.983, 'prec': 0.359, 'rec': 0.383, 'f1': 0.371, 'rt': 13}, '75': {'acc': 0.983, 'prec': 0.352, 'rec': 0.381, 'f1': 0.366, 'rt': 10}}, 'sv': {'100': {'acc': 0.982, 'prec': 0.11, 'rec': 0.057, 'f1': 0.075, 'rt': 2}, '90': {'acc': 0.982, 'prec': 0.039, 'rec': 0.016, 'f1': 0.022, 'rt': 2}, '75': {'acc': 0.983, 'prec': 0.046, 'rec': 0.016, 'f1': 0.023, 'rt': 2}}, 'lr': {'100': {'acc': 0.988, 'prec': 0.652, 'rec': 0.194, 'f1': 0.299, 'rt': 1}, '90': {'acc': 0.988, 'prec': 0.667, 'rec': 0.197, 'f1': 0.304, 'rt': 1}, '75': {'acc': 0.988, 'prec': 0.673, 'rec': 0.187, 'f1': 0.292, 'rt': 1}}, 'mlp': {'100': {'acc': 0.988, 'prec': 0.556, 'rec': 0.412, 'f1': 0.473, 'rt': 48}, '90': {'acc': 0.989, 'prec': 0.61, 'rec': 0.345, 'f1': 0.44, 'rt': 45}, '75': {'acc': 0.987, 'prec': 0.523, 'rec': 0.352, 'f1': 0.421, 'rt': 35}}}, {'dt': {'100': {'acc': 0.983, 'prec': 0.348, 'rec': 0.32, 'f1': 0.334, 'rt': 19}, '90': {'acc': 0.983, 'prec': 0.348, 'rec': 0.336, 'f1': 0.342, 'rt': 16}, '75': {'acc': 0.983, 'prec': 0.334, 'rec': 0.349, 'f1': 0.341, 'rt': 11}}, 'sv': {'100': {'acc': 0.975, 'prec': 0.095, 'rec': 0.106, 'f1': 0.1, 'rt': 2}, '90': {'acc': 0.98, 'prec': 0.094, 'rec': 0.067, 'f1': 0.078, 'rt': 2}, '75': {'acc': 0.946, 'prec': 0.039, 'rec': 0.134, 'f1': 0.061, 'rt': 2}}, 'lr': {'100': {'acc': 0.988, 'prec': 0.655, 'rec': 0.186, 'f1': 0.29, 'rt': 1}, '90': {'acc': 0.988, 'prec': 0.635, 'rec': 0.189, 'f1': 0.291, 'rt': 1}, '75': {'acc': 0.988, 'prec': 0.654, 'rec': 0.176, 'f1': 0.277, 'rt': 1}}, 'mlp': {'100': {'acc': 0.988, 'prec': 0.577, 'rec': 0.32, 'f1': 0.412, 'rt': 47}, '90': {'acc': 0.987, 'prec': 0.526, 'rec': 0.336, 'f1': 0.41, 'rt': 44}, '75': {'acc': 0.987, 'prec': 0.496, 'rec': 0.307, 'f1': 0.38, 'rt': 35}}}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-184-f57884473f68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Process the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mbalance_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_balance_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalance_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-34d78c7ff10e>\u001b[0m in \u001b[0;36mprocess_balance_results\u001b[0;34m(models, results)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mmodel_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnext_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-34d78c7ff10e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mmodel_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnext_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '0'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLkCm2nQW0sy",
        "outputId": "cadf9a02-4abc-462d-f296-dade0f3164de"
      },
      "source": [
        "hcf_sub_list = ['100', '90', '75']\n",
        "\n",
        "for m in model_set.keys():\n",
        "  print('Model', m)\n",
        "  stat_set = [res[m] for res in fold_results ]\n",
        "  run_stats(stat_set, 'rec')\n",
        "  run_stats(stat_set, 'prec')\n",
        "  run_stats(stat_set, 'f1')\n",
        "\n",
        "hcf_results = process_exp_results(hcf_sub_list, model_set.keys(), fold_results)\n",
        "\n",
        "print(hcf_results)\n",
        "\n",
        "for subsize in hcf_sub_list:\n",
        "  print(f'\\n\\n====== Size = {subsize} ========')\n",
        "  print_results(hcf_results[subsize])\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dt\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.382  0.377  0.364\n",
            "1  0.344  0.336  0.331\n",
            "2  0.349  0.359  0.328\n",
            "3  0.396  0.383  0.381\n",
            "4  0.320  0.336  0.349\n",
            "[0.358, 0.358, 0.351]\n",
            "[1.6, 1.8, 2.6]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=2.8000000000000043, pvalue=0.24659696394160596)\n",
            "--Stat test: prec\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.380  0.383  0.355\n",
            "1  0.365  0.364  0.340\n",
            "2  0.344  0.354  0.343\n",
            "3  0.398  0.359  0.352\n",
            "4  0.348  0.348  0.334\n",
            "[0.367, 0.362, 0.345]\n",
            "[1.4, 1.6, 3.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=7.894736842105264, pvalue=0.019305438773144105)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.381  0.380  0.360\n",
            "1  0.354  0.349  0.336\n",
            "2  0.347  0.356  0.336\n",
            "3  0.397  0.371  0.366\n",
            "4  0.334  0.342  0.341\n",
            "[0.363, 0.36, 0.348]\n",
            "[1.6, 1.6, 2.8]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=4.799999999999997, pvalue=0.09071795328941264)\n",
            "Model sv\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.168  0.127  0.034\n",
            "1  0.160  0.147  0.067\n",
            "2  0.057  0.183  0.168\n",
            "3  0.057  0.016  0.016\n",
            "4  0.106  0.067  0.134\n",
            "[0.11, 0.108, 0.084]\n",
            "[1.6, 2.0, 2.4]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=1.3684210526315834, pvalue=0.50448835267872)\n",
            "--Stat test: prec\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.064  0.047  0.125\n",
            "1  0.074  0.036  0.063\n",
            "2  0.108  0.051  0.070\n",
            "3  0.110  0.039  0.046\n",
            "4  0.095  0.094  0.039\n",
            "[0.09, 0.053, 0.069]\n",
            "[1.2, 2.8, 2.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=6.400000000000006, pvalue=0.04076220397836611)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.093  0.069  0.053\n",
            "1  0.101  0.058  0.065\n",
            "2  0.075  0.080  0.099\n",
            "3  0.075  0.022  0.023\n",
            "4  0.100  0.078  0.061\n",
            "[0.089, 0.061, 0.06]\n",
            "[1.4, 2.4, 2.2]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=2.8000000000000043, pvalue=0.24659696394160596)\n",
            "Model lr\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.178  0.176  0.163\n",
            "1  0.189  0.181  0.168\n",
            "2  0.199  0.191  0.171\n",
            "3  0.194  0.197  0.187\n",
            "4  0.186  0.189  0.176\n",
            "[0.189, 0.187, 0.173]\n",
            "[1.4, 1.6, 3.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=7.6000000000000085, pvalue=0.0223707718561655)\n",
            "--Stat test: prec\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.639  0.648  0.685\n",
            "1  0.689  0.693  0.663\n",
            "2  0.616  0.632  0.606\n",
            "3  0.652  0.667  0.673\n",
            "4  0.655  0.635  0.654\n",
            "[0.65, 0.655, 0.656]\n",
            "[2.2, 1.8, 2.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=0.4000000000000057, pvalue=0.8187307530779795)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.279  0.276  0.263\n",
            "1  0.296  0.287  0.268\n",
            "2  0.301  0.294  0.266\n",
            "3  0.299  0.304  0.292\n",
            "4  0.290  0.291  0.277\n",
            "[0.293, 0.29, 0.273]\n",
            "[1.4, 1.6, 3.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=7.6000000000000085, pvalue=0.0223707718561655)\n",
            "Model mlp\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.367  0.344  0.416\n",
            "1  0.331  0.346  0.359\n",
            "2  0.385  0.341  0.341\n",
            "3  0.412  0.345  0.352\n",
            "4  0.320  0.336  0.307\n",
            "[0.363, 0.342, 0.355]\n",
            "[1.8, 2.2, 2.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=0.736842105263161, pvalue=0.6918258252705161)\n",
            "--Stat test: prec\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.526  0.576  0.488\n",
            "1  0.549  0.424  0.535\n",
            "2  0.584  0.600  0.579\n",
            "3  0.556  0.610  0.523\n",
            "4  0.577  0.526  0.496\n",
            "[0.558, 0.547, 0.524]\n",
            "[1.6, 1.6, 2.8]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=4.799999999999997, pvalue=0.09071795328941264)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "     100     90     75\n",
            "0  0.432  0.430  0.449\n",
            "1  0.413  0.381  0.430\n",
            "2  0.464  0.435  0.429\n",
            "3  0.473  0.440  0.421\n",
            "4  0.412  0.410  0.380\n",
            "[0.439, 0.419, 0.422]\n",
            "[1.4, 2.4, 2.2]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=2.8000000000000043, pvalue=0.24659696394160596)\n",
            "{'100': {'dt': {'acc': 0.984, 'rec': 0.358, 'prec': 0.367, 'f1': 0.363, 'rt': 17.0}, 'sv': {'acc': 0.972, 'rec': 0.11, 'prec': 0.09, 'f1': 0.089, 'rt': 2.0}, 'lr': {'acc': 0.988, 'rec': 0.189, 'prec': 0.65, 'f1': 0.293, 'rt': 1.0}, 'mlp': {'acc': 0.988, 'rec': 0.363, 'prec': 0.558, 'f1': 0.439, 'rt': 48.2}}, '90': {'dt': {'acc': 0.983, 'rec': 0.358, 'prec': 0.362, 'f1': 0.36, 'rt': 14.0}, 'sv': {'acc': 0.96, 'rec': 0.108, 'prec': 0.053, 'f1': 0.061, 'rt': 2.0}, 'lr': {'acc': 0.988, 'rec': 0.187, 'prec': 0.655, 'f1': 0.29, 'rt': 1.0}, 'mlp': {'acc': 0.988, 'rec': 0.342, 'prec': 0.547, 'f1': 0.419, 'rt': 45.2}}, '75': {'dt': {'acc': 0.983, 'rec': 0.351, 'prec': 0.345, 'f1': 0.348, 'rt': 11.0}, 'sv': {'acc': 0.97, 'rec': 0.084, 'prec': 0.069, 'f1': 0.06, 'rt': 2.0}, 'lr': {'acc': 0.988, 'rec': 0.173, 'prec': 0.656, 'f1': 0.273, 'rt': 1.0}, 'mlp': {'acc': 0.987, 'rec': 0.355, 'prec': 0.524, 'f1': 0.422, 'rt': 35.2}}}\n",
            "\n",
            "\n",
            "====== Size = 100 ========\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dt\n",
            "acc: 0.984\n",
            "rec: 0.358\n",
            "prec: 0.367\n",
            "f1: 0.363\n",
            "rt: 17.0\n",
            "\n",
            "\n",
            "sv\n",
            "acc: 0.972\n",
            "rec: 0.11\n",
            "prec: 0.09\n",
            "f1: 0.089\n",
            "rt: 2.0\n",
            "\n",
            "\n",
            "lr\n",
            "acc: 0.988\n",
            "rec: 0.189\n",
            "prec: 0.65\n",
            "f1: 0.293\n",
            "rt: 1.0\n",
            "\n",
            "\n",
            "mlp\n",
            "acc: 0.988\n",
            "rec: 0.363\n",
            "prec: 0.558\n",
            "f1: 0.439\n",
            "rt: 48.2\n",
            "\n",
            "\n",
            "====== Size = 90 ========\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dt\n",
            "acc: 0.983\n",
            "rec: 0.358\n",
            "prec: 0.362\n",
            "f1: 0.36\n",
            "rt: 14.0\n",
            "\n",
            "\n",
            "sv\n",
            "acc: 0.96\n",
            "rec: 0.108\n",
            "prec: 0.053\n",
            "f1: 0.061\n",
            "rt: 2.0\n",
            "\n",
            "\n",
            "lr\n",
            "acc: 0.988\n",
            "rec: 0.187\n",
            "prec: 0.655\n",
            "f1: 0.29\n",
            "rt: 1.0\n",
            "\n",
            "\n",
            "mlp\n",
            "acc: 0.988\n",
            "rec: 0.342\n",
            "prec: 0.547\n",
            "f1: 0.419\n",
            "rt: 45.2\n",
            "\n",
            "\n",
            "====== Size = 75 ========\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dt\n",
            "acc: 0.983\n",
            "rec: 0.351\n",
            "prec: 0.345\n",
            "f1: 0.348\n",
            "rt: 11.0\n",
            "\n",
            "\n",
            "sv\n",
            "acc: 0.97\n",
            "rec: 0.084\n",
            "prec: 0.069\n",
            "f1: 0.06\n",
            "rt: 2.0\n",
            "\n",
            "\n",
            "lr\n",
            "acc: 0.988\n",
            "rec: 0.173\n",
            "prec: 0.656\n",
            "f1: 0.273\n",
            "rt: 1.0\n",
            "\n",
            "\n",
            "mlp\n",
            "acc: 0.987\n",
            "rec: 0.355\n",
            "prec: 0.524\n",
            "f1: 0.422\n",
            "rt: 35.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCGL_ALZhdXx",
        "outputId": "04d703b8-679d-4ae5-e477-443c92e2649e"
      },
      "source": [
        "save_obj(fold_results, 'hcf_results')"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noqQN3WEfaND"
      },
      "source": [
        "## Dimension Experiment\n",
        "What is the optimal embedding size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dri90r-KkJ6U",
        "outputId": "b297252e-68c2-427b-e4ce-8e9952da8f62"
      },
      "source": [
        "embedding_matrix_100, tokenizer_100 = get_embeddings_and_tokenizer(contracts, 100)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400001 word vectors.\n",
            "Vocab size: 25441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RD-p_Q0kb6z",
        "outputId": "e13b010c-9979-4a44-9bba-e20487feabfe"
      },
      "source": [
        "features, labels = get_features_labels_for_element(elem_contracts, elem_docs, tokenizer_100, embedding_matrix_100, element_id)\n",
        "X100 = np.array(features)\n",
        "y100 = np.array(labels)\n",
        "print('Initial data shape:', X100.shape)\n",
        "print('----')"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "Initial data shape: (149363, 1507)\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXVnRd2mkT23"
      },
      "source": [
        "folds = get_k_folds(num_folds, X, y)\n",
        "\n",
        "fold_results = []\n",
        "\n",
        "for i in range(num_folds):\n",
        "  print(f'\\n ===== FOLD {i} =====')\n",
        "\n",
        "  # Get the sets from the fold\n",
        "  X_train, X_test = X[folds[i]['train']], X[folds[i]['test']]\n",
        "  X100_train, X100_test = X100[folds[i]['train']], X100[folds[i]['test']]\n",
        "  y_train, y_test = y[folds[i]['train']], y[folds[i]['test']]\n",
        "\n",
        "  # Scale\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "\n",
        "  # Scale\n",
        "  sc100 = StandardScaler()\n",
        "  X100_train = sc100.fit_transform(X100_train)\n",
        "  X100_test = sc100.transform(X100_test)\n",
        "\n",
        "  model_results = {}\n",
        "  for m in model_set.keys():\n",
        "    model_results[m] = {}\n",
        "    print('running: ', m)\n",
        "    model = model_set[m]\n",
        "    model_results[m]['50'] = run_model(model, X_train, X_test, y_train, y_test)\n",
        "    model_results[m]['100'] = run_model(model, X100_train, X100_test, y_train, y_test)\n",
        "\n",
        "  fold_results.append(model_results)\n",
        "\n",
        "print(fold_results)\n",
        "print(balance_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdasll9gmWaW"
      },
      "source": [
        "dim_list = ['50', '100']\n",
        "\n",
        "for m in model_set.keys():\n",
        "  print('Model', m)\n",
        "  stat_set = [res[m] for res in fold_results ]\n",
        "  run_stats(stat_set, 'rec')\n",
        "  run_stats(stat_set, 'prec')\n",
        "  run_stats(stat_set, 'f1')\n",
        "\n",
        "dim_results = process_exp_results(dim_list, model_set.keys(), fold_results)\n",
        "\n",
        "print(dim_results)\n",
        "\n",
        "for dim in dim_list:\n",
        "  print(f'\\n\\n====== Dimension = {dim} ========')\n",
        "  print_results(dim_results[dim])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I32S1jOy4DI9",
        "outputId": "d8dafe59-b307-4283-f878-cd384212d7a6"
      },
      "source": [
        "save_obj(fold_results, 'dim_results')"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf4ybCzcpR3F"
      },
      "source": [
        "## PCA Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LsUZi6bj35Ct",
        "outputId": "1d746522-dd90-4c9f-c3b2-e41ec8bce358"
      },
      "source": [
        "folds = get_k_folds(num_folds, X, y)\n",
        "\n",
        "fold_results = []\n",
        "\n",
        "for i in range(num_folds):\n",
        "  print(f'\\n ===== FOLD {i} =====')\n",
        "\n",
        "  # Get the sets from the fold\n",
        "  X_train, X_test = X[folds[i]['train']], X[folds[i]['test']]\n",
        "  y_train, y_test = y[folds[i]['train']], y[folds[i]['test']]\n",
        "\n",
        "  # Undersampling\n",
        "  X_train, y_train = undersample(X_train, y_train, 0.05)\n",
        "\n",
        "  # Scale\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "\n",
        "  # PCA 1\n",
        "  pca1 = PCA(n_components=0.97, svd_solver='full')\n",
        "  Xp1_train = pca1.fit_transform(X_train)\n",
        "  Xp1_test = pca1.transform(X_test)\n",
        "  print('PCA1 Feature dimension:', len(Xp1_train[0]))\n",
        "\n",
        "  # PCA 2\n",
        "  pca2 = PCA(n_components=0.95, svd_solver='full')\n",
        "  Xp2_train = pca2.fit_transform(X_train)\n",
        "  Xp2_test = pca2.transform(X_test)\n",
        "  print('PCA2 Feature dimension:', len(Xp2_train[0]))\n",
        "\n",
        "  model_results = {}\n",
        "  for m in model_set.keys():\n",
        "    model_results[m] = {}\n",
        "    print('running: ', m)\n",
        "    model = model_set[m]\n",
        "    model_results[m]['NO_PCA'] = run_model(model, X_train, X_test, y_train, y_test)\n",
        "    model_results[m]['PCA1'] = run_model(model, Xp1_train, Xp1_test, y_train, y_test)\n",
        "    model_results[m]['PCA2'] = run_model(model, Xp2_train, Xp2_test, y_train, y_test)\n",
        "\n",
        "  fold_results.append(model_results)\n",
        "\n",
        "print(fold_results)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 0 =====\n",
            "[0 1] [117943   1547] 119490\n",
            "[0 1] [30940  1547] 32487\n",
            "PCA1 Feature dimension: 1156\n",
            "PCA2 Feature dimension: 1040\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 1 =====\n",
            "[0 1] [117943   1547] 119490\n",
            "[0 1] [30940  1547] 32487\n",
            "PCA1 Feature dimension: 1157\n",
            "PCA2 Feature dimension: 1041\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 2 =====\n",
            "[0 1] [117943   1547] 119490\n",
            "[0 1] [30940  1547] 32487\n",
            "PCA1 Feature dimension: 1157\n",
            "PCA2 Feature dimension: 1041\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 3 =====\n",
            "[0 1] [117943   1548] 119491\n",
            "[0 1] [30960  1548] 32508\n",
            "PCA1 Feature dimension: 1156\n",
            "PCA2 Feature dimension: 1040\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 4 =====\n",
            "[0 1] [117944   1547] 119491\n",
            "[0 1] [30940  1547] 32487\n",
            "PCA1 Feature dimension: 1157\n",
            "PCA2 Feature dimension: 1041\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=25).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'dt': {'NO_PCA': {'acc': 0.973, 'prec': 0.228, 'rec': 0.45, 'f1': 0.303, 'rt': 53}, 'PCA1': {'acc': 0.963, 'prec': 0.156, 'rec': 0.421, 'f1': 0.228, 'rt': 111}, 'PCA2': {'acc': 0.966, 'prec': 0.165, 'rec': 0.393, 'f1': 0.233, 'rt': 99}}, 'sv': {'NO_PCA': {'acc': 0.971, 'prec': 0.044, 'rec': 0.059, 'f1': 0.051, 'rt': 2}, 'PCA1': {'acc': 0.969, 'prec': 0.048, 'rec': 0.075, 'f1': 0.058, 'rt': 2}, 'PCA2': {'acc': 0.967, 'prec': 0.047, 'rec': 0.078, 'f1': 0.058, 'rt': 1}}, 'lr': {'NO_PCA': {'acc': 0.981, 'prec': 0.353, 'rec': 0.553, 'f1': 0.431, 'rt': 1}, 'PCA1': {'acc': 0.982, 'prec': 0.363, 'rec': 0.537, 'f1': 0.433, 'rt': 1}, 'PCA2': {'acc': 0.983, 'prec': 0.384, 'rec': 0.553, 'f1': 0.453, 'rt': 1}}, 'mlp': {'NO_PCA': {'acc': 0.984, 'prec': 0.426, 'rec': 0.643, 'f1': 0.512, 'rt': 27}, 'PCA1': {'acc': 0.987, 'prec': 0.513, 'rec': 0.574, 'f1': 0.541, 'rt': 32}, 'PCA2': {'acc': 0.987, 'prec': 0.5, 'rec': 0.558, 'f1': 0.527, 'rt': 30}}}, {'dt': {'NO_PCA': {'acc': 0.969, 'prec': 0.203, 'rec': 0.475, 'f1': 0.284, 'rt': 53}, 'PCA1': {'acc': 0.964, 'prec': 0.136, 'rec': 0.336, 'f1': 0.194, 'rt': 109}, 'PCA2': {'acc': 0.965, 'prec': 0.134, 'rec': 0.313, 'f1': 0.188, 'rt': 99}}, 'sv': {'NO_PCA': {'acc': 0.973, 'prec': 0.05, 'rec': 0.059, 'f1': 0.054, 'rt': 2}, 'PCA1': {'acc': 0.97, 'prec': 0.061, 'rec': 0.09, 'f1': 0.073, 'rt': 2}, 'PCA2': {'acc': 0.969, 'prec': 0.061, 'rec': 0.098, 'f1': 0.075, 'rt': 1}}, 'lr': {'NO_PCA': {'acc': 0.978, 'prec': 0.313, 'rec': 0.563, 'f1': 0.402, 'rt': 1}, 'PCA1': {'acc': 0.979, 'prec': 0.326, 'rec': 0.561, 'f1': 0.413, 'rt': 1}, 'PCA2': {'acc': 0.981, 'prec': 0.354, 'rec': 0.558, 'f1': 0.433, 'rt': 1}}, 'mlp': {'NO_PCA': {'acc': 0.983, 'prec': 0.399, 'rec': 0.574, 'f1': 0.47, 'rt': 29}, 'PCA1': {'acc': 0.987, 'prec': 0.497, 'rec': 0.587, 'f1': 0.538, 'rt': 33}, 'PCA2': {'acc': 0.987, 'prec': 0.497, 'rec': 0.568, 'f1': 0.53, 'rt': 30}}}, {'dt': {'NO_PCA': {'acc': 0.97, 'prec': 0.194, 'rec': 0.416, 'f1': 0.264, 'rt': 52}, 'PCA1': {'acc': 0.965, 'prec': 0.148, 'rec': 0.359, 'f1': 0.21, 'rt': 111}, 'PCA2': {'acc': 0.963, 'prec': 0.148, 'rec': 0.385, 'f1': 0.213, 'rt': 98}}, 'sv': {'NO_PCA': {'acc': 0.977, 'prec': 0.074, 'rec': 0.07, 'f1': 0.072, 'rt': 2}, 'PCA1': {'acc': 0.976, 'prec': 0.071, 'rec': 0.072, 'f1': 0.072, 'rt': 2}, 'PCA2': {'acc': 0.975, 'prec': 0.068, 'rec': 0.075, 'f1': 0.071, 'rt': 1}}, 'lr': {'NO_PCA': {'acc': 0.98, 'prec': 0.351, 'rec': 0.605, 'f1': 0.444, 'rt': 1}, 'PCA1': {'acc': 0.981, 'prec': 0.364, 'rec': 0.579, 'f1': 0.447, 'rt': 1}, 'PCA2': {'acc': 0.983, 'prec': 0.391, 'rec': 0.576, 'f1': 0.466, 'rt': 1}}, 'mlp': {'NO_PCA': {'acc': 0.989, 'prec': 0.563, 'rec': 0.568, 'f1': 0.566, 'rt': 28}, 'PCA1': {'acc': 0.984, 'prec': 0.414, 'rec': 0.636, 'f1': 0.502, 'rt': 33}, 'PCA2': {'acc': 0.984, 'prec': 0.428, 'rec': 0.594, 'f1': 0.497, 'rt': 33}}}, {'dt': {'NO_PCA': {'acc': 0.97, 'prec': 0.198, 'rec': 0.438, 'f1': 0.273, 'rt': 54}, 'PCA1': {'acc': 0.966, 'prec': 0.142, 'rec': 0.329, 'f1': 0.198, 'rt': 112}, 'PCA2': {'acc': 0.963, 'prec': 0.138, 'rec': 0.35, 'f1': 0.198, 'rt': 99}}, 'sv': {'NO_PCA': {'acc': 0.947, 'prec': 0.047, 'rec': 0.161, 'f1': 0.073, 'rt': 2}, 'PCA1': {'acc': 0.936, 'prec': 0.045, 'rec': 0.192, 'f1': 0.072, 'rt': 2}, 'PCA2': {'acc': 0.932, 'prec': 0.043, 'rec': 0.202, 'f1': 0.071, 'rt': 1}}, 'lr': {'NO_PCA': {'acc': 0.981, 'prec': 0.365, 'rec': 0.591, 'f1': 0.451, 'rt': 1}, 'PCA1': {'acc': 0.981, 'prec': 0.362, 'rec': 0.588, 'f1': 0.448, 'rt': 1}, 'PCA2': {'acc': 0.981, 'prec': 0.349, 'rec': 0.544, 'f1': 0.426, 'rt': 1}}, 'mlp': {'NO_PCA': {'acc': 0.985, 'prec': 0.441, 'rec': 0.575, 'f1': 0.499, 'rt': 28}, 'PCA1': {'acc': 0.987, 'prec': 0.513, 'rec': 0.562, 'f1': 0.536, 'rt': 33}, 'PCA2': {'acc': 0.983, 'prec': 0.411, 'rec': 0.642, 'f1': 0.502, 'rt': 31}}}, {'dt': {'NO_PCA': {'acc': 0.973, 'prec': 0.218, 'rec': 0.434, 'f1': 0.29, 'rt': 55}, 'PCA1': {'acc': 0.964, 'prec': 0.133, 'rec': 0.32, 'f1': 0.188, 'rt': 114}, 'PCA2': {'acc': 0.965, 'prec': 0.147, 'rec': 0.351, 'f1': 0.207, 'rt': 103}}, 'sv': {'NO_PCA': {'acc': 0.977, 'prec': 0.052, 'rec': 0.044, 'f1': 0.048, 'rt': 2}, 'PCA1': {'acc': 0.975, 'prec': 0.056, 'rec': 0.057, 'f1': 0.057, 'rt': 2}, 'PCA2': {'acc': 0.975, 'prec': 0.057, 'rec': 0.059, 'f1': 0.058, 'rt': 1}}, 'lr': {'NO_PCA': {'acc': 0.978, 'prec': 0.314, 'rec': 0.599, 'f1': 0.412, 'rt': 1}, 'PCA1': {'acc': 0.981, 'prec': 0.345, 'rec': 0.548, 'f1': 0.424, 'rt': 1}, 'PCA2': {'acc': 0.98, 'prec': 0.339, 'rec': 0.568, 'f1': 0.425, 'rt': 1}}, 'mlp': {'NO_PCA': {'acc': 0.985, 'prec': 0.43, 'rec': 0.571, 'f1': 0.491, 'rt': 29}, 'PCA1': {'acc': 0.986, 'prec': 0.469, 'rec': 0.561, 'f1': 0.511, 'rt': 35}, 'PCA2': {'acc': 0.985, 'prec': 0.435, 'rec': 0.581, 'f1': 0.498, 'rt': 34}}}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-d65ab44e5460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalance_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'balance_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNciuQZA42ET",
        "outputId": "5ee10e6e-5041-4324-8151-b56920020823"
      },
      "source": [
        "pca_list = ['NO_PCA', 'PCA1', 'PCA2']\n",
        "\n",
        "for m in model_set.keys():\n",
        "  print('Model', m)\n",
        "  stat_set = [res[m] for res in fold_results ]\n",
        "  run_stats(stat_set, 'rec')\n",
        "  run_stats(stat_set, 'prec')\n",
        "  run_stats(stat_set, 'f1')\n",
        "\n",
        "pca_results = process_exp_results(pca_list, model_set.keys(), fold_results)\n",
        "\n",
        "print(pca_results)\n",
        "\n",
        "for dim in pca_list:\n",
        "  print(f'\\n\\n====== Dimension = {dim} ========')\n",
        "  print_results(pca_results[dim])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dt\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.450  0.421  0.393\n",
            "1   0.475  0.336  0.313\n",
            "2   0.416  0.359  0.385\n",
            "3   0.438  0.329  0.350\n",
            "4   0.434  0.320  0.351\n",
            "[0.443, 0.353, 0.358]\n",
            "[1.0, 2.6, 2.4]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=7.6000000000000085, pvalue=0.0223707718561655)\n",
            "--Stat test: prec\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.228  0.156  0.165\n",
            "1   0.203  0.136  0.134\n",
            "2   0.194  0.148  0.148\n",
            "3   0.198  0.142  0.138\n",
            "4   0.218  0.133  0.147\n",
            "[0.208, 0.143, 0.146]\n",
            "[1.0, 2.4, 2.6]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=7.894736842105264, pvalue=0.019305438773144105)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.303  0.228  0.233\n",
            "1   0.284  0.194  0.188\n",
            "2   0.264  0.210  0.213\n",
            "3   0.273  0.198  0.198\n",
            "4   0.290  0.188  0.207\n",
            "[0.283, 0.204, 0.208]\n",
            "[1.0, 2.6, 2.4]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=8.315789473684218, pvalue=0.01564045054832703)\n",
            "Model sv\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.059  0.075  0.078\n",
            "1   0.059  0.090  0.098\n",
            "2   0.070  0.072  0.075\n",
            "3   0.161  0.192  0.202\n",
            "4   0.044  0.057  0.059\n",
            "[0.079, 0.097, 0.102]\n",
            "[3.0, 2.0, 1.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=10.0, pvalue=0.006737946999085468)\n",
            "--Stat test: prec\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.044  0.048  0.047\n",
            "1   0.050  0.061  0.061\n",
            "2   0.074  0.071  0.068\n",
            "3   0.047  0.045  0.043\n",
            "4   0.052  0.056  0.057\n",
            "[0.053, 0.056, 0.055]\n",
            "[2.2, 1.6, 2.2]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=0.736842105263161, pvalue=0.6918258252705161)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.051  0.058  0.058\n",
            "1   0.054  0.073  0.075\n",
            "2   0.072  0.072  0.071\n",
            "3   0.073  0.072  0.071\n",
            "4   0.048  0.057  0.058\n",
            "[0.06, 0.066, 0.067]\n",
            "[2.2, 1.8, 2.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=0.7777777777777809, pvalue=0.6778095780054493)\n",
            "Model lr\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.553  0.537  0.553\n",
            "1   0.563  0.561  0.558\n",
            "2   0.605  0.579  0.576\n",
            "3   0.591  0.588  0.544\n",
            "4   0.599  0.548  0.568\n",
            "[0.582, 0.563, 0.56]\n",
            "[1.0, 2.4, 2.6]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=6.421052631578957, pvalue=0.04033537853783436)\n",
            "--Stat test: prec\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.353  0.363  0.384\n",
            "1   0.313  0.326  0.354\n",
            "2   0.351  0.364  0.391\n",
            "3   0.365  0.362  0.349\n",
            "4   0.314  0.345  0.339\n",
            "[0.339, 0.352, 0.363]\n",
            "[2.6, 1.8, 1.6]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=2.8000000000000043, pvalue=0.24659696394160596)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.431  0.433  0.453\n",
            "1   0.402  0.413  0.433\n",
            "2   0.444  0.447  0.466\n",
            "3   0.451  0.448  0.426\n",
            "4   0.412  0.424  0.425\n",
            "[0.428, 0.433, 0.441]\n",
            "[2.6, 2.0, 1.4]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=3.6000000000000014, pvalue=0.16529888822158642)\n",
            "Model mlp\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.643  0.574  0.558\n",
            "1   0.574  0.587  0.568\n",
            "2   0.568  0.636  0.594\n",
            "3   0.575  0.562  0.642\n",
            "4   0.571  0.561  0.581\n",
            "[0.586, 0.584, 0.589]\n",
            "[2.0, 2.0, 2.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=0.0, pvalue=1.0)\n",
            "--Stat test: prec\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.426  0.513  0.500\n",
            "1   0.399  0.497  0.497\n",
            "2   0.563  0.414  0.428\n",
            "3   0.441  0.513  0.411\n",
            "4   0.430  0.469  0.435\n",
            "[0.452, 0.481, 0.454]\n",
            "[2.4, 1.4, 2.2]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=2.2105263157894752, pvalue=0.33112373295101094)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "   NO_PCA   PCA1   PCA2\n",
            "0   0.512  0.541  0.527\n",
            "1   0.470  0.538  0.530\n",
            "2   0.566  0.502  0.497\n",
            "3   0.499  0.536  0.502\n",
            "4   0.491  0.511  0.498\n",
            "[0.508, 0.526, 0.511]\n",
            "[2.6, 1.2, 2.2]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=5.200000000000003, pvalue=0.0742735782143338)\n",
            "{'NO_PCA': {'dt': {'acc': 0.971, 'rec': 0.443, 'prec': 0.208, 'f1': 0.283, 'rt': 53.4}, 'sv': {'acc': 0.969, 'rec': 0.079, 'prec': 0.053, 'f1': 0.06, 'rt': 2.0}, 'lr': {'acc': 0.98, 'rec': 0.582, 'prec': 0.339, 'f1': 0.428, 'rt': 1.0}, 'mlp': {'acc': 0.985, 'rec': 0.586, 'prec': 0.452, 'f1': 0.508, 'rt': 28.2}}, 'PCA1': {'dt': {'acc': 0.964, 'rec': 0.353, 'prec': 0.143, 'f1': 0.204, 'rt': 111.4}, 'sv': {'acc': 0.965, 'rec': 0.097, 'prec': 0.056, 'f1': 0.066, 'rt': 2.0}, 'lr': {'acc': 0.981, 'rec': 0.563, 'prec': 0.352, 'f1': 0.433, 'rt': 1.0}, 'mlp': {'acc': 0.986, 'rec': 0.584, 'prec': 0.481, 'f1': 0.526, 'rt': 33.2}}, 'PCA2': {'dt': {'acc': 0.964, 'rec': 0.358, 'prec': 0.146, 'f1': 0.208, 'rt': 99.6}, 'sv': {'acc': 0.964, 'rec': 0.102, 'prec': 0.055, 'f1': 0.067, 'rt': 1.0}, 'lr': {'acc': 0.982, 'rec': 0.56, 'prec': 0.363, 'f1': 0.441, 'rt': 1.0}, 'mlp': {'acc': 0.985, 'rec': 0.589, 'prec': 0.454, 'f1': 0.511, 'rt': 31.6}}}\n",
            "\n",
            "\n",
            "====== Dimension = NO_PCA ========\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dt\n",
            "acc: 0.971\n",
            "rec: 0.443\n",
            "prec: 0.208\n",
            "f1: 0.283\n",
            "rt: 53.4\n",
            "\n",
            "\n",
            "sv\n",
            "acc: 0.969\n",
            "rec: 0.079\n",
            "prec: 0.053\n",
            "f1: 0.06\n",
            "rt: 2.0\n",
            "\n",
            "\n",
            "lr\n",
            "acc: 0.98\n",
            "rec: 0.582\n",
            "prec: 0.339\n",
            "f1: 0.428\n",
            "rt: 1.0\n",
            "\n",
            "\n",
            "mlp\n",
            "acc: 0.985\n",
            "rec: 0.586\n",
            "prec: 0.452\n",
            "f1: 0.508\n",
            "rt: 28.2\n",
            "\n",
            "\n",
            "====== Dimension = PCA1 ========\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dt\n",
            "acc: 0.964\n",
            "rec: 0.353\n",
            "prec: 0.143\n",
            "f1: 0.204\n",
            "rt: 111.4\n",
            "\n",
            "\n",
            "sv\n",
            "acc: 0.965\n",
            "rec: 0.097\n",
            "prec: 0.056\n",
            "f1: 0.066\n",
            "rt: 2.0\n",
            "\n",
            "\n",
            "lr\n",
            "acc: 0.981\n",
            "rec: 0.563\n",
            "prec: 0.352\n",
            "f1: 0.433\n",
            "rt: 1.0\n",
            "\n",
            "\n",
            "mlp\n",
            "acc: 0.986\n",
            "rec: 0.584\n",
            "prec: 0.481\n",
            "f1: 0.526\n",
            "rt: 33.2\n",
            "\n",
            "\n",
            "====== Dimension = PCA2 ========\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dt\n",
            "acc: 0.964\n",
            "rec: 0.358\n",
            "prec: 0.146\n",
            "f1: 0.208\n",
            "rt: 99.6\n",
            "\n",
            "\n",
            "sv\n",
            "acc: 0.964\n",
            "rec: 0.102\n",
            "prec: 0.055\n",
            "f1: 0.067\n",
            "rt: 1.0\n",
            "\n",
            "\n",
            "lr\n",
            "acc: 0.982\n",
            "rec: 0.56\n",
            "prec: 0.363\n",
            "f1: 0.441\n",
            "rt: 1.0\n",
            "\n",
            "\n",
            "mlp\n",
            "acc: 0.985\n",
            "rec: 0.589\n",
            "prec: 0.454\n",
            "f1: 0.511\n",
            "rt: 31.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYMCa2qx42rG",
        "outputId": "37f6f7b5-8df6-4757-d38d-8e8c3eb8532a"
      },
      "source": [
        "save_obj(pca_results, 'pca_results')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq3qpdif6rIQ"
      },
      "source": [
        "## Full Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1OGCWCwJ60l"
      },
      "source": [
        "embedding_size = 50  # 100\n",
        "balance_ratio = 0.05 # 0.05\n",
        "num_folds = 5        # 5\n",
        "subset_size = 50     # -1\n",
        "\n",
        "model_set = {\n",
        "  'dt': DecisionTreeClassifier(max_depth=10),\n",
        "  'sv': SVC(max_iter=50),\n",
        "  'lr': LogisticRegression(max_iter=250),\n",
        "  'mlp': MLPClassifier(max_iter=50),\n",
        "}"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr-q2Wq0J8rp",
        "outputId": "d6d3a62b-17c1-4b16-e298-164bdd712ec1"
      },
      "source": [
        "# Get globals\n",
        "contracts = load_obj('contracts')\n",
        "docs = load_obj('docs')\n",
        "embedding_matrix, tokenizer = get_embeddings_and_tokenizer(contracts, embedding_size)\n",
        "\n",
        "print('Number of contracts: ', len(contracts))\n",
        "print('Vocab length: ', len(tokenizer.word_index))\n",
        "print('Embedding size: ', embedding_matrix.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400001 word vectors.\n",
            "Vocab size: 25441\n",
            "Number of contracts:  429\n",
            "Vocab length:  25441\n",
            "Embedding size:  (25442, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjB57ITM6txv",
        "outputId": "f1b5c855-0368-4a87-d0b8-75a010839aef"
      },
      "source": [
        "element_id = 4\n",
        "\n",
        "print(f'\\n ============== ELEMENT {element_id} ==================')\n",
        "# Get all contracts/docs for the element\n",
        "elem_contracts, elem_docs = get_contracts_docs_with_element(contracts, docs, element_id)\n",
        "print('Num contracts considered:', len(elem_contracts))\n",
        "\n",
        "# For full experiment, will be ignoring\n",
        "if subset_size > 0:\n",
        "  elem_contracts = elem_contracts[0:subset_size]\n",
        "  elem_docs = elem_docs[0:subset_size]\n",
        "\n",
        "# Build the features\n",
        "X, y = get_features_labels_for_element(elem_contracts, elem_docs, tokenizer, embedding_matrix, element_id)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print('Initial data shape:', X.shape)\n",
        "print('----')\n",
        "\n",
        "# Make some room\n",
        "print('...Cleanup')\n",
        "del elem_contracts\n",
        "del elem_docs\n",
        "gc.collect()\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ============== ELEMENT 4 ==================\n",
            "Num contracts considered: 148\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "Initial data shape: (1124338, 957)\n",
            "----\n",
            "...Cleanup\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1W5ZbWRjTSK",
        "outputId": "5a597656-441d-4444-8374-ddd02f93b8d8"
      },
      "source": [
        "\n",
        "# Get 5 folds\n",
        "folds = get_k_folds(num_folds, X, y)\n",
        "\n",
        "fold_results = []\n",
        "\n",
        "for i in range(num_folds):\n",
        "  print(f'\\n ===== FOLD {i} =====')\n",
        "\n",
        "  # Get the sets from the fold\n",
        "  X_train, X_test = X[folds[i]['train']], X[folds[i]['test']]\n",
        "  y_train, y_test = y[folds[i]['train']], y[folds[i]['test']]\n",
        "\n",
        "  # Balance\n",
        "  X_train, y_train = undersample(X_train, y_train, balance_ratio)\n",
        "\n",
        "  # Scale\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "\n",
        "  model_results = {}\n",
        "  for m in model_set.keys():\n",
        "    print('running: ', m)\n",
        "    model = model_set[m]\n",
        "    model_results[m] = run_model(model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "  fold_results.append(model_results)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 0 =====\n",
            "[0 1] [886593  12877] 899470\n",
            "[0 1] [257540  12877] 270417\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 1 =====\n",
            "[0 1] [886593  12877] 899470\n",
            "[0 1] [257540  12877] 270417\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 2 =====\n",
            "[0 1] [886594  12876] 899470\n",
            "[0 1] [257520  12876] 270396\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 3 =====\n",
            "[0 1] [886594  12877] 899471\n",
            "[0 1] [257540  12877] 270417\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== FOLD 4 =====\n",
            "[0 1] [886594  12877] 899471\n",
            "[0 1] [257540  12877] 270417\n",
            "running:  dt\n",
            "running:  sv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oXXSjl0KOaB",
        "outputId": "1265bce4-8f8a-46be-dec1-78799c048683"
      },
      "source": [
        "  # Save results\n",
        "  save_obj(fold_results, f'full_results_{element_id}')\n",
        "\n",
        "  # Run stats\n",
        "  run_stats(fold_results, 'rec')\n",
        "  run_stats(fold_results, 'f1')\n",
        "\n",
        "  # Process the results\n",
        "  element_result = process_iter_results(model_set.keys(), fold_results)\n",
        "  #all_results[str(element_id)] = element_result\n",
        "  \n",
        "  print(f'\\n ELEMENT {element_id} RESULTS:')\n",
        "  print_results(element_result)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved\n",
            "--Stat test: rec\n",
            "\n",
            "---------\n",
            "      dt     sv   lr    mlp\n",
            "0  0.001  0.041  0.0  0.062\n",
            "1  0.002  0.037  0.0  0.069\n",
            "2  0.001  0.041  0.0  0.068\n",
            "3  0.002  0.029  0.0  0.072\n",
            "4  0.003  0.034  0.0  0.067\n",
            "[0.002, 0.036, 0.0, 0.068]\n",
            "[3.0, 2.0, 4.0, 1.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=15.0, pvalue=0.0018166489665723214)\n",
            "--Stat test: f1\n",
            "\n",
            "---------\n",
            "      dt     sv   lr    mlp\n",
            "0  0.002  0.015  0.0  0.036\n",
            "1  0.003  0.013  0.0  0.037\n",
            "2  0.001  0.015  0.0  0.039\n",
            "3  0.003  0.011  0.0  0.037\n",
            "4  0.006  0.012  0.0  0.039\n",
            "[0.003, 0.013, 0.0, 0.038]\n",
            "[3.0, 2.0, 4.0, 1.0]\n",
            "Using Friedman test\n",
            "Scipy: FriedmanchisquareResult(statistic=15.0, pvalue=0.0018166489665723214)\n",
            "\n",
            " ELEMENT 4 RESULTS:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dt\n",
            "acc: 0.985\n",
            "prec: 0.05\n",
            "rec: 0.002\n",
            "f1: 0.003\n",
            "rt: 136.6\n",
            "\n",
            "\n",
            "sv\n",
            "acc: 0.923\n",
            "prec: 0.008\n",
            "rec: 0.036\n",
            "f1: 0.013\n",
            "rt: 21.8\n",
            "\n",
            "\n",
            "lr\n",
            "acc: 0.986\n",
            "prec: 0.0\n",
            "rec: 0.0\n",
            "f1: 0.0\n",
            "rt: 55.4\n",
            "\n",
            "\n",
            "mlp\n",
            "acc: 0.95\n",
            "prec: 0.026\n",
            "rec: 0.068\n",
            "f1: 0.038\n",
            "rt: 354.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5nZ70b6Ca0D"
      },
      "source": [
        "## General Testing\n",
        "Setup for general testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTXEpKA9uVgd"
      },
      "source": [
        "embedding_size = 50"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qioejRHaCY-O"
      },
      "source": [
        "# Prep the globals (Skip if already saved)\n",
        "with tf.device('/device:GPU:0'):\n",
        "  # Get contracts and all the tokenized docs\n",
        "  contracts, docs = get_contracts_and_docs()\n",
        "\n",
        "  # Build tokenizer and embeddings\n",
        "  embedding_matrix, tokenizer = get_embeddings_and_tokenizer(contracts, embedding_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C2STRGOCJbv"
      },
      "source": [
        "# Save\n",
        "# save_obj(contracts, 'contracts')\n",
        "# save_obj(docs, 'docs')\n",
        "# save_obj(embedding_matrix, f'embedding_matrix_{embedding_size}')\n",
        "# save_obj(tokenizer, f'tokenizer_{embedding_size}')\n",
        "\n",
        "# Load\n",
        "contracts = load_obj('contracts')\n",
        "docs = load_obj('docs')\n",
        "embedding_matrix = load_obj(f'embedding_matrix_{embedding_size}')\n",
        "tokenizer = load_obj(f'tokenizer_{embedding_size}')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48UOxGRBRUiB",
        "outputId": "f326332a-9ff2-4201-e278-da7e9dcd936c"
      },
      "source": [
        "print(len(contracts), len(docs))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429 429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhotmcxn5M0i",
        "outputId": "26382865-1082-46f4-b0ae-65cd1d038f1a"
      },
      "source": [
        "# Element to test on\n",
        "element_id = 1\n",
        "\n",
        "## Want to find the contracts that actually have this element\n",
        "elem_contracts, elem_docs = get_contracts_docs_with_element(contracts, docs, element_id)\n",
        "\n",
        "print(len(elem_contracts), len(elem_docs))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "428 428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7GpU7gSW00i",
        "outputId": "2e1b5b6a-00a1-4eec-a0a5-6590228e1885"
      },
      "source": [
        "# Build the features\n",
        "## This takes a while\n",
        "features, labels = get_features_labels_for_element(elem_contracts, elem_docs, tokenizer, embedding_matrix, element_id)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFUYyngYCpVa",
        "outputId": "fe21bddb-1002-4bb4-821a-207b6929a7ec"
      },
      "source": [
        "X,y = features, labels\n",
        "\n",
        "# Undersampling\n",
        "X, y = undersample(X,y, 0.1)\n",
        "\n",
        "# Train/Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, shuffle=True)\n",
        "\n",
        "# Scale the data\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Dimensionality reduction\n",
        "X_train, pca = perform_pca(X_train, 0.95)\n",
        "X_test = pca.transform(X_test)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init 1507\n",
            "new 1301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc8gLwdAIbIK",
        "outputId": "caa4349c-bf08-495d-db5d-b1ba00c6f7a4"
      },
      "source": [
        "print(X_train.shape)\n",
        "\n",
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "perc0 = round(counts[0]/len(y_train), 3)\n",
        "perc1 = round(counts[1]/len(y_train), 3)\n",
        "print(unique, counts, perc0, perc1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53660, 1301)\n",
            "[0 1] [48782  4878] 0.909 0.091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HT8LsmfB3oz",
        "outputId": "8df1e9bd-ba8e-40bb-d64d-f40981659f52"
      },
      "source": [
        "dt_weights = {0:1.0, 1:10.0}\n",
        "model_set = {\n",
        "  #'dt': DecisionTreeClassifier(class_weight=dt_weights, max_depth=30),\n",
        "  #'lr': LogisticRegression(),\n",
        "  #'rf': RandomForestClassifier(class_weight=dt_weights, max_depth=30),\n",
        "  'dt': DecisionTreeClassifier(max_depth=30),\n",
        "  'rf': RandomForestClassifier(max_depth=30),\n",
        "  #'svc': SVC(),\n",
        "  #'gb': GradientBoostingClassifier(),\n",
        "  'mlp': MLPClassifier(max_iter=10) \n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for m in model_set.keys():\n",
        "  print('running: ', m)\n",
        "  model = model_set[m]\n",
        "  results[m] = run_model(model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "final_results = process_results(model_set.keys(), results)\n",
        "print_results(final_results)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running:  dt\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     96692\n",
            "           1       0.34      0.37      0.35      1434\n",
            "\n",
            "    accuracy                           0.98     98126\n",
            "   macro avg       0.66      0.68      0.67     98126\n",
            "weighted avg       0.98      0.98      0.98     98126\n",
            "\n",
            "running:  rf\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     96692\n",
            "           1       0.77      0.21      0.33      1434\n",
            "\n",
            "    accuracy                           0.99     98126\n",
            "   macro avg       0.88      0.61      0.66     98126\n",
            "weighted avg       0.99      0.99      0.98     98126\n",
            "\n",
            "running:  mlp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     96692\n",
            "           1       0.61      0.44      0.51      1434\n",
            "\n",
            "    accuracy                           0.99     98126\n",
            "   macro avg       0.80      0.72      0.75     98126\n",
            "weighted avg       0.99      0.99      0.99     98126\n",
            "\n",
            "\n",
            "\n",
            "dt\n",
            "acc: 0.98\n",
            "prec: 0.338\n",
            "rec: 0.37\n",
            "f1: 0.353\n",
            "rt: 11643\n",
            "rf\n",
            "acc: 0.988\n",
            "prec: 0.774\n",
            "rec: 0.212\n",
            "f1: 0.333\n",
            "rt: 36630\n",
            "mlp\n",
            "acc: 0.988\n",
            "prec: 0.614\n",
            "rec: 0.441\n",
            "f1: 0.514\n",
            "rt: 23456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi4JGgWMEQf_"
      },
      "source": [
        "# Extra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms-ULKDmJ38j"
      },
      "source": [
        "### Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMCL42C8J5dH"
      },
      "source": [
        "# model = Pipeline([\n",
        "#     ('sampling', SMOTE()),\n",
        "#     ('clf', DecisionTreeClassifier())\n",
        "# ])\n",
        "\n",
        "tune_model = DecisionTreeClassifier()\n",
        "\n",
        "param_grid = [\n",
        "  {\n",
        "      'clf__criterion': ['gini', 'entropy'], \n",
        "      'clf__max_depth': [5, 10, 20, 40, None],\n",
        "      'clf__max_features': ['auto', 'sqrt', 'log2', None],\n",
        "      'clf__min_samples_split': [2, 3, 4, 5],\n",
        "  },\n",
        "]\n",
        "\n",
        "grid = GridSearchCV(model, param_grid, scoring='recall')\n",
        "res = grid.fit(X_train, y_train)\n",
        "\n",
        "#res_df = pd.DataFrame(res.cv_results_)\n",
        "\n",
        "#print(res_df)\n",
        "print('Best Estimator', res.best_estimator_)\n",
        "print('Best Params', res.best_params_)\n",
        "print('Best Accuracy', res.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgNvlppzCD_J"
      },
      "source": [
        "### Identify Windows for each element\n",
        "- This is just a one-time thing\n",
        "- Result is doc_ranges\n",
        "- May want to print out some plots for reporting purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "QBPhofexXcqT",
        "outputId": "10e58da2-2073-4da7-d6bd-0e1651925625"
      },
      "source": [
        "  plt.hist(all_vals)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([357., 787., 260., 142.,   0., 670.,   0.,   0., 508., 730.]),\n",
              " array([  303. ,  1555.8,  2808.6,  4061.4,  5314.2,  6567. ,  7819.8,\n",
              "         9072.6, 10325.4, 11578.2, 12831. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Xh4kM5HZB_pO",
        "outputId": "1a54085f-ba27-425a-b5c2-9df21bbe9983"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "id_window_trigger = True\n",
        "\n",
        "if id_window_trigger:\n",
        "\n",
        "  # Element to test on\n",
        "  element_id = 3\n",
        "\n",
        "  ## Want to find the contracts that actually have this element\n",
        "  elem_contracts, elem_docs = get_contracts_docs_with_element(contracts, docs, element_id)\n",
        "\n",
        "  curr_min = 999999999\n",
        "  curr_max = 0 \n",
        "\n",
        "  all_vals = []\n",
        "\n",
        "  for i,c in enumerate(elem_contracts):\n",
        "    doc = elem_docs[i]\n",
        "    #answer_span = get_labels(c, element_id, doc)\n",
        "\n",
        "    qa = c['qas'][element_id]\n",
        "\n",
        "    # Get the span of the answer tokens\n",
        "    # Concatenate together so we have a list of tokens that are part of the label\n",
        "    answers = qa['answers']\n",
        "    answer_spans = get_answer_spans(doc, answers)\n",
        "    concat_ans_spans = np.concatenate(answer_spans) if len(answer_spans) > 0 else []\n",
        "\n",
        "    #print(concat_ans_spans)\n",
        "    all_vals.extend(concat_ans_spans)\n",
        "\n",
        "    curr_min = min(curr_min, min(concat_ans_spans, default=9999999))\n",
        "    curr_max = max(curr_max, max(concat_ans_spans, default=0))\n",
        "\n",
        "  print(curr_min, curr_max)\n",
        "\n",
        "  print('vals',all_vals)\n",
        "  plt.hist(all_vals, bins=50)\n",
        "\n",
        "# Results (token window)\n",
        "## 0: 0 15639... search 0 -1000\n",
        "## 1: 0 17426... search 0 - 2000\n",
        "## 2: 0 12899... search 0 - 1000\n",
        "## 3: 303 12831... search 300 - 12831 - damn. they're everywhere\n",
        "## 4: 401 15333... search 400 - 12000\n",
        "\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303 12831\n",
            "vals [6602, 6603, 6604, 6605, 6606, 6607, 6608, 6609, 6610, 6611, 6612, 6613, 6614, 6615, 6616, 6617, 6618, 6619, 6620, 6621, 6622, 6623, 6624, 6625, 6626, 6627, 6628, 6629, 6630, 6631, 6632, 6633, 6634, 6635, 6636, 6637, 6638, 6639, 6640, 6641, 6642, 6643, 7018, 7019, 7020, 7021, 7022, 7023, 7024, 7025, 7026, 7027, 7028, 7029, 7030, 7031, 7032, 7033, 7034, 7035, 7036, 7037, 7038, 7039, 7040, 7041, 7042, 7043, 7044, 7045, 7046, 7047, 7048, 7049, 7050, 7051, 7052, 7053, 7054, 7055, 7056, 7057, 7058, 7059, 7060, 7061, 7062, 7063, 7064, 7065, 7066, 7067, 7068, 7069, 7070, 7071, 7072, 7073, 7074, 7075, 7076, 7077, 7078, 7079, 7080, 7081, 7082, 7083, 7084, 7085, 6661, 6662, 6663, 6664, 6665, 6666, 6667, 6668, 6669, 6670, 6671, 6672, 6673, 6674, 6675, 6676, 6677, 6678, 6679, 6680, 6681, 6682, 6683, 6684, 6685, 6686, 6687, 6688, 6689, 6690, 6691, 6692, 6715, 6716, 6717, 6718, 6719, 6720, 6721, 6722, 6723, 6724, 6725, 6726, 6727, 6728, 6729, 6730, 6731, 6732, 6733, 6734, 6644, 6645, 6646, 6647, 6648, 6649, 6650, 6651, 6652, 6653, 6654, 6655, 6656, 6735, 6736, 6737, 6738, 6739, 6740, 6741, 6742, 6743, 6744, 6745, 6746, 6747, 6748, 6749, 6750, 6751, 6752, 6753, 6754, 6755, 6756, 6757, 6758, 6759, 6760, 6761, 6762, 6763, 6764, 6765, 6766, 6767, 6768, 6769, 6770, 6771, 6772, 6773, 6774, 6775, 6776, 6777, 6778, 6779, 6780, 6781, 6782, 6783, 6784, 6785, 6786, 6787, 6788, 6789, 6790, 6791, 6792, 6793, 6794, 6795, 6796, 6797, 6798, 6799, 6800, 6801, 6802, 6803, 6804, 6805, 6806, 6807, 6808, 6809, 6810, 6811, 6816, 6817, 6818, 6819, 6820, 6821, 6822, 6823, 6824, 6825, 6826, 6827, 6828, 6829, 6830, 6831, 6832, 6833, 6834, 6835, 6836, 6837, 6838, 6839, 6840, 6841, 6842, 6843, 6844, 6845, 6846, 6847, 6848, 6849, 6850, 6851, 6852, 6853, 6854, 6855, 6856, 6857, 6858, 6859, 6860, 6861, 6862, 6863, 6864, 6865, 6866, 6867, 6868, 6869, 6870, 6871, 6872, 6873, 6874, 6875, 6876, 6877, 6878, 6879, 6880, 6881, 6882, 6883, 6884, 6885, 6886, 6887, 6888, 6889, 6890, 6891, 6892, 6893, 6894, 6895, 6896, 6897, 6898, 6899, 6900, 6901, 6902, 6903, 6904, 6905, 6906, 6907, 6908, 6909, 6910, 6911, 6912, 6913, 6914, 6915, 6916, 6917, 6918, 6919, 6920, 6921, 6922, 6923, 6924, 6925, 6926, 6927, 6928, 6929, 6930, 6931, 6932, 6933, 6934, 6935, 6936, 6937, 6938, 6939, 6940, 6941, 6942, 6943, 6944, 6945, 6946, 6947, 6948, 6949, 6950, 6951, 6952, 6953, 6954, 6955, 6956, 6957, 6958, 6959, 6960, 6961, 6962, 6963, 6964, 6965, 6966, 6967, 6968, 6969, 6970, 6971, 6972, 6973, 6974, 6975, 6976, 6977, 6978, 6979, 6980, 6981, 6982, 6983, 6984, 6985, 6986, 6987, 6988, 6989, 6990, 6991, 6992, 6993, 6994, 6995, 6996, 6997, 6998, 6999, 7000, 7001, 7002, 7003, 7004, 7005, 7006, 7007, 7008, 7009, 7010, 7011, 7012, 7013, 12673, 12674, 12675, 12676, 12677, 12678, 12679, 12680, 12681, 12682, 12683, 12684, 12685, 12686, 12687, 12688, 12689, 12690, 12691, 12692, 12693, 12694, 12695, 12696, 12697, 12698, 12699, 12700, 12701, 12702, 12703, 12704, 12705, 12706, 12707, 12708, 12709, 12710, 12711, 12712, 12713, 12714, 12715, 12716, 12717, 12718, 12719, 12720, 12721, 12722, 12723, 12724, 12725, 12726, 12727, 12728, 12729, 12730, 12731, 12732, 12733, 12734, 12735, 12736, 12737, 12738, 12739, 12740, 12741, 12742, 12743, 12744, 12745, 12746, 12747, 12748, 12749, 12750, 12751, 12752, 12753, 12754, 12755, 12756, 12757, 12758, 12759, 12760, 12761, 12762, 12763, 12764, 12765, 12766, 12767, 12768, 12769, 12770, 12771, 12772, 12773, 12774, 12775, 12776, 12777, 12778, 12779, 12780, 12781, 12782, 12783, 12784, 12785, 12786, 12787, 12788, 12789, 12790, 12791, 12792, 12793, 12794, 12795, 12550, 12551, 12552, 12553, 12554, 12555, 12556, 12557, 12558, 12559, 12560, 12561, 12562, 12563, 12564, 12565, 12566, 12567, 12568, 12569, 12570, 12571, 12572, 12573, 12574, 12575, 12576, 12577, 12578, 12579, 12580, 12581, 12582, 12583, 12584, 12806, 12807, 12808, 12809, 12810, 12811, 12812, 12813, 12814, 12815, 12816, 12817, 12818, 12819, 12820, 12821, 12822, 12823, 12824, 12825, 12826, 12827, 12828, 12829, 12830, 12831, 12592, 12593, 12594, 12595, 12596, 12597, 12598, 12599, 12600, 12601, 12602, 12603, 12604, 12605, 12606, 12607, 12608, 12609, 12610, 12611, 12612, 12613, 12614, 12615, 12616, 12617, 12618, 12619, 12620, 12621, 12622, 12623, 12624, 12625, 12626, 12627, 12628, 12629, 12630, 12631, 12632, 12633, 12634, 12635, 12636, 12637, 12638, 12639, 12640, 12641, 12642, 12643, 12644, 12645, 12646, 12647, 12648, 12649, 12650, 12651, 12652, 12653, 12654, 12655, 12656, 12657, 12658, 12659, 12660, 12661, 12662, 12663, 12664, 12665, 12666, 12667, 12668, 12498, 12499, 12500, 12501, 12502, 12503, 12504, 12505, 12506, 12507, 12508, 12509, 12510, 12511, 12512, 12513, 12514, 12515, 12516, 12517, 12518, 12519, 12520, 12521, 12522, 12523, 12524, 12525, 12526, 12527, 12528, 12529, 12530, 12531, 12532, 12533, 12534, 12535, 12536, 12537, 12538, 12539, 12540, 12541, 12542, 12543, 12544, 12545, 12546, 12547, 12548, 12549, 3383, 3384, 3385, 3386, 3387, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3408, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3421, 3422, 3423, 3424, 3425, 3426, 3427, 3428, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 12623, 12624, 12625, 12626, 12627, 12628, 12629, 12630, 12631, 12632, 12633, 12634, 12635, 12636, 12637, 12638, 12639, 12640, 12641, 12642, 12643, 12644, 12645, 12646, 12647, 12648, 12649, 12650, 12651, 12652, 12653, 12654, 12655, 12656, 12657, 12658, 12659, 12660, 12661, 12662, 12663, 12664, 12665, 12666, 7264, 7265, 7266, 7267, 7268, 7269, 7270, 7271, 7272, 7273, 7274, 7275, 7276, 7277, 7278, 7279, 7280, 7281, 7282, 7283, 7284, 7285, 7286, 7287, 7288, 7289, 7290, 7291, 7292, 7293, 7294, 7295, 7296, 7297, 7298, 7299, 7300, 7301, 7302, 7303, 7304, 7305, 7306, 7307, 7308, 7309, 7310, 7311, 7312, 7313, 7314, 7315, 7316, 7317, 7318, 7319, 7320, 7321, 7322, 7323, 7324, 7325, 7326, 7327, 7328, 7329, 7330, 7331, 7332, 7333, 7334, 7335, 7336, 7337, 7338, 7339, 7340, 7341, 7342, 7343, 7344, 7345, 7346, 7347, 7348, 7349, 7350, 7351, 7352, 7353, 7354, 7355, 7356, 7357, 7358, 7359, 7360, 7361, 7362, 7363, 7364, 7365, 7366, 7367, 7368, 7369, 7370, 7371, 7372, 7373, 7374, 7375, 7376, 7377, 7378, 7379, 7380, 7381, 7382, 7383, 7384, 7385, 7386, 7387, 7388, 7389, 7390, 7391, 7392, 7393, 7394, 7395, 7396, 7397, 7398, 7399, 7400, 7401, 7402, 7403, 7404, 7405, 7406, 7407, 7408, 7409, 7410, 7411, 7412, 7413, 7414, 7216, 7217, 7218, 7219, 7220, 7221, 7222, 7223, 7224, 7225, 7226, 7227, 7228, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7236, 7237, 7238, 7239, 7240, 7241, 7242, 7243, 7244, 7156, 7157, 7158, 7159, 7160, 7161, 7162, 7163, 7164, 7165, 7166, 7167, 7168, 7169, 7170, 7171, 7172, 7173, 7174, 7175, 7176, 7177, 7178, 7179, 7180, 7181, 7182, 7183, 7184, 7185, 7186, 7187, 7188, 7189, 7190, 7191, 7192, 7193, 7194, 7195, 11259, 11260, 11261, 11262, 11263, 11264, 11265, 11266, 11267, 11268, 11269, 11270, 11271, 11272, 11273, 11274, 11275, 11276, 11277, 11278, 11279, 11280, 11281, 11282, 11283, 11284, 11285, 11286, 11287, 11288, 11289, 11290, 11291, 11292, 11293, 11294, 11295, 11296, 11297, 11298, 11299, 11300, 11301, 11302, 11303, 11304, 11305, 11306, 11307, 11308, 11309, 11310, 11311, 11312, 11313, 11314, 11315, 11316, 11317, 11318, 11319, 11320, 11321, 11322, 11323, 11324, 11325, 11326, 11327, 11328, 11329, 11330, 11331, 11332, 11333, 11334, 11335, 11336, 11337, 11338, 11339, 11340, 11341, 11342, 11343, 11344, 11345, 11346, 11347, 11348, 11349, 11350, 11351, 11352, 11353, 11354, 11355, 11356, 11357, 11358, 11359, 11360, 11361, 11362, 11363, 11364, 11365, 11366, 11367, 11368, 11369, 11370, 11371, 11372, 11373, 11374, 11375, 11376, 11377, 11378, 11379, 11380, 11381, 11382, 11383, 11384, 11385, 11386, 11387, 11388, 11389, 11390, 11391, 11392, 11393, 11394, 11395, 11396, 11397, 11398, 11399, 11400, 11401, 11402, 11403, 11404, 11405, 11116, 11117, 11118, 11119, 11120, 11121, 11122, 11123, 11124, 11125, 11126, 11127, 11128, 11129, 11130, 11131, 11132, 11133, 11134, 11135, 11136, 11137, 11138, 11139, 11140, 11141, 11142, 11143, 11144, 11145, 11146, 11147, 11148, 11149, 11150, 11151, 11152, 11153, 11154, 11155, 11156, 11157, 11158, 11159, 11160, 11161, 11162, 11163, 11164, 11165, 11166, 11167, 11168, 11169, 11170, 11171, 11172, 11173, 11174, 11175, 11176, 11177, 11178, 11179, 11180, 11181, 11182, 11183, 11184, 11185, 11186, 11187, 11188, 11189, 11190, 11191, 11192, 11193, 11194, 11195, 11196, 11197, 11198, 11199, 11200, 11201, 11202, 11203, 11204, 11205, 11206, 11207, 11208, 11209, 11210, 11211, 11212, 11213, 11436, 11437, 11438, 11439, 11440, 11441, 11442, 11443, 11444, 11445, 11446, 11447, 11448, 11449, 11450, 11451, 11452, 11453, 11454, 11455, 11456, 11457, 11458, 11459, 11460, 11461, 11462, 11463, 11464, 11465, 11466, 11591, 11592, 11593, 11594, 11595, 11596, 11597, 11598, 11599, 11600, 11601, 11602, 11603, 11604, 11605, 11606, 11607, 11608, 11609, 11610, 11611, 11612, 11613, 11614, 11615, 11616, 11617, 11618, 11619, 11620, 11621, 11622, 11623, 11624, 11625, 11626, 11627, 11628, 11629, 11630, 11631, 11632, 11633, 11634, 11635, 11636, 11637, 11638, 11639, 11640, 11641, 11642, 11643, 11644, 11645, 11646, 11647, 11648, 11649, 11650, 11651, 11652, 11653, 11654, 11655, 11656, 11657, 11658, 11659, 11660, 11661, 11662, 11663, 11664, 11665, 11666, 11667, 11668, 11669, 11670, 11671, 11672, 11673, 11674, 11675, 11676, 11677, 11678, 11679, 11680, 11681, 11682, 11683, 11684, 11685, 11686, 11687, 11688, 11689, 11690, 11691, 11692, 11693, 11694, 11695, 11696, 11697, 11698, 11699, 11700, 11701, 11702, 11703, 11704, 11705, 11706, 11707, 11708, 11709, 11710, 11711, 11712, 11713, 11714, 11715, 11716, 11717, 11718, 11719, 11720, 11721, 11722, 11723, 11724, 11725, 11726, 11727, 11728, 11729, 11730, 11731, 11732, 11733, 11734, 11735, 11736, 11737, 11738, 11739, 11740, 11741, 11742, 11743, 11744, 11745, 11746, 11747, 11748, 11749, 11750, 11751, 11752, 11753, 11754, 11755, 11756, 11757, 11758, 11759, 11760, 11761, 11762, 11763, 11764, 11765, 11766, 11767, 11768, 11769, 11770, 11771, 11772, 11773, 11774, 11775, 11776, 11777, 11778, 11779, 11780, 11781, 11782, 11783, 11784, 11785, 11786, 11787, 11788, 11789, 11790, 11791, 11792, 11793, 11794, 11795, 11796, 11797, 11798, 11799, 11800, 11801, 11802, 11803, 11804, 11805, 11806, 11807, 11808, 11809, 11810, 11811, 11812, 11813, 11814, 11815, 11816, 11817, 11818, 11819, 11820, 11821, 11822, 11823, 11824, 11825, 11826, 11827, 11828, 11829, 11830, 11831, 11832, 11833, 11834, 11835, 11836, 11837, 11838, 11839, 11840, 11841, 11842, 11843, 11844, 11845, 11846, 11847, 11848, 11849, 11850, 11851, 11852, 11853, 11854, 11855, 11856, 11857, 11858, 11859, 11860, 11861, 11862, 11863, 11864, 11865, 11866, 11867, 11868, 11869, 11870, 11871, 11872, 11873, 11874, 11875, 11876, 11877, 11878, 11879, 11880, 11881, 11882, 11883, 11884, 11885, 11886, 11887, 11888, 11889, 11890, 11891, 11892, 11893, 11894, 11895, 11896, 11897, 11898, 11899, 11900, 11901, 11902, 11903, 11904, 11905, 11906, 11907, 11908, 11909, 11910, 11911, 11912, 11913, 11914, 11915, 11916, 11917, 11918, 11919, 11920, 11921, 11922, 11923, 11924, 11925, 11926, 11927, 11928, 11929, 11930, 11931, 11932, 11933, 11934, 11935, 11936, 11937, 11938, 11939, 11940, 11941, 11942, 11943, 11944, 11945, 11946, 11947, 11948, 11949, 11950, 11951, 11952, 11953, 11954, 11955, 11956, 11957, 11958, 11959, 11960, 11961, 11962, 11963, 10806, 10807, 10808, 10809, 10810, 10811, 10812, 10813, 10814, 10815, 10816, 10817, 10818, 10819, 10820, 10821, 10822, 10823, 10824, 10825, 10826, 10827, 10828, 10829, 10830, 10831, 10832, 10833, 10834, 10835, 10836, 10837, 10838, 10839, 10840, 10841, 10842, 10843, 10844, 10845, 10846, 10847, 10848, 10849, 10850, 10851, 10852, 10853, 10854, 10855, 10856, 10857, 10858, 10859, 10860, 10861, 10862, 10863, 10864, 10865, 10866, 10867, 10868, 10869, 10870, 10871, 10872, 10873, 10874, 10875, 10876, 10877, 10878, 10879, 10880, 10881, 10882, 10883, 10884, 10885, 10886, 10887, 10888, 10889, 10890, 10891, 10892, 10893, 10894, 10895, 10896, 10897, 10898, 10899, 10900, 10901, 10902, 10903, 10904, 10905, 10906, 10907, 10908, 10909, 10910, 10911, 10912, 10913, 10914, 10915, 10916, 10917, 10918, 10919, 10920, 10921, 10922, 10923, 10924, 10925, 10926, 10927, 10928, 10929, 10930, 10931, 10932, 10933, 10934, 10935, 10936, 10937, 10938, 10939, 10940, 10941, 10942, 10943, 10944, 10945, 10946, 10947, 10948, 10949, 10950, 10951, 10952, 10953, 10954, 10955, 10956, 10957, 10958, 10959, 10960, 10961, 10962, 10963, 10964, 10965, 10966, 10967, 10968, 10969, 10970, 10971, 10972, 10973, 10974, 10975, 10976, 10977, 10978, 10979, 10980, 10981, 10982, 10983, 10984, 10985, 10986, 10987, 10988, 10989, 10990, 10991, 10992, 10993, 10994, 10995, 10996, 10997, 10998, 10999, 11000, 11001, 11002, 11003, 11004, 11005, 11006, 11007, 11008, 11009, 11010, 11011, 11012, 11013, 11014, 11015, 11016, 11017, 11018, 11019, 11020, 11021, 11022, 11023, 11024, 11025, 11026, 11027, 11028, 11029, 11030, 11031, 11032, 11033, 11034, 11035, 11036, 11037, 4603, 4604, 4605, 4606, 4607, 4608, 4609, 4610, 4611, 4612, 4613, 4614, 4615, 4616, 4617, 4618, 4619, 4620, 4621, 4622, 4623, 4624, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4632, 4633, 4634, 4635, 4636, 4637, 4638, 4639, 4640, 4641, 4642, 4643, 4644, 4645, 4646, 4647, 4648, 4649, 4650, 4651, 4652, 4653, 4654, 4655, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666, 4667, 4668, 4669, 4670, 4671, 4672, 4673, 4674, 4675, 4676, 4677, 4678, 4679, 4680, 4681, 4682, 4683, 4684, 4685, 4686, 4687, 4688, 4689, 4690, 4691, 4692, 4693, 4694, 4695, 4696, 4697, 4698, 4699, 4700, 4701, 4702, 4703, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4712, 4713, 4714, 4715, 4716, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4724, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4734, 4735, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4744, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2646]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1segM3K0bcZ1",
        "outputId": "f3374f59-13ce-473f-fe60-de31d5595d0f"
      },
      "source": [
        "doc_ranges = [\n",
        "  [0,1000],\n",
        "  [0,1600],\n",
        "  [0,3000],\n",
        "  [300,13000],\n",
        "  [400,12000]\n",
        "]\n",
        "\n",
        "# Element to test on\n",
        "element_id = 4\n",
        "\n",
        "## Want to find the contracts that actually have this element\n",
        "elem_contracts, elem_docs = get_contracts_docs_with_element(contracts, docs, element_id)\n",
        "\n",
        "doc_range = doc_ranges[element_id]\n",
        "\n",
        "labels = []\n",
        "\n",
        "for i, contract in enumerate(elem_contracts):\n",
        "  doc = elem_docs[i]\n",
        "  doc_sub = doc[doc_range[0]: doc_range[1]]\n",
        "  \n",
        "  next_labels = get_labels(contract, element_id, doc_sub)\n",
        "    \n",
        "  labels.extend(next_labels)\n",
        "\n",
        "print(len(labels))\n",
        "\n",
        "# now get unique\n",
        "u,c = np.unique(labels, return_counts=True)\n",
        "print(u,c, sum(c), c[1]*100/sum(c))\n",
        "print(sum(c), c[1], round(100*c[1]/sum(c),3))"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1124338\n",
            "[0 1] [1108242   16096] 1124338 1.4315979714285205\n",
            "1124338 16096 1.432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEMTbQ5WlfKl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}